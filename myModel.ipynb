{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S89AJpQYG3du"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlnQdsrDh9AX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "pickle_in = open(\"finalModelX\",\"rb\")\n",
    "x_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"finalModely\",\"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "\n",
    "x_train = x_train/255.0\n",
    "y_train = to_categorical(y_train,NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Lq0YDUYiTMN"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(40, 40, 1), name='input')\n",
    "\n",
    "x = Conv2D(24, kernel_size=(6, 6), strides=1)(inputs)\n",
    "x = BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "\n",
    "x = Conv2D(48, kernel_size=(5, 5), strides=2)(x)\n",
    "x = BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=(4, 4), strides=2)(x)\n",
    "x = BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(200)(x)\n",
    "x = BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "\n",
    "predications = Dense(NUM_CLASSES, activation='softmax', name='output')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predications)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBzYWAEAiwzx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 40, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 35, 35, 24)        888       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 35, 35, 24)        72        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 35, 35, 24)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 35, 35, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16, 16, 48)        144       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          49216     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 7, 7, 64)          192       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               627400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 200)               600       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 709,370\n",
      "Trainable params: 708,698\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McycGoh0itz2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49740 samples, validate on 5527 samples\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0201.\n",
      "Epoch 1/20\n",
      "49740/49740 [==============================] - ETA: 23:53 - loss: 2.7827 - acc: 0.10 - ETA: 6:01 - loss: 2.8801 - acc: 0.1895 - ETA: 3:27 - loss: 2.6918 - acc: 0.202 - ETA: 2:26 - loss: 2.5785 - acc: 0.205 - ETA: 1:53 - loss: 2.4563 - acc: 0.224 - ETA: 1:32 - loss: 2.3990 - acc: 0.225 - ETA: 1:18 - loss: 2.3304 - acc: 0.238 - ETA: 1:07 - loss: 2.2745 - acc: 0.250 - ETA: 1:00 - loss: 2.2232 - acc: 0.261 - ETA: 53s - loss: 2.1940 - acc: 0.268 - ETA: 48s - loss: 2.1655 - acc: 0.27 - ETA: 43s - loss: 2.1117 - acc: 0.29 - ETA: 40s - loss: 2.0690 - acc: 0.30 - ETA: 37s - loss: 2.0368 - acc: 0.31 - ETA: 34s - loss: 1.9982 - acc: 0.32 - ETA: 32s - loss: 1.9666 - acc: 0.34 - ETA: 30s - loss: 1.9303 - acc: 0.35 - ETA: 29s - loss: 1.9015 - acc: 0.36 - ETA: 27s - loss: 1.8676 - acc: 0.37 - ETA: 26s - loss: 1.8294 - acc: 0.38 - ETA: 24s - loss: 1.7895 - acc: 0.39 - ETA: 23s - loss: 1.7610 - acc: 0.41 - ETA: 22s - loss: 1.7259 - acc: 0.42 - ETA: 21s - loss: 1.6935 - acc: 0.43 - ETA: 20s - loss: 1.6640 - acc: 0.44 - ETA: 20s - loss: 1.6336 - acc: 0.45 - ETA: 19s - loss: 1.6048 - acc: 0.45 - ETA: 18s - loss: 1.5783 - acc: 0.46 - ETA: 17s - loss: 1.5509 - acc: 0.47 - ETA: 17s - loss: 1.5232 - acc: 0.48 - ETA: 16s - loss: 1.4976 - acc: 0.49 - ETA: 16s - loss: 1.4735 - acc: 0.50 - ETA: 15s - loss: 1.4528 - acc: 0.50 - ETA: 15s - loss: 1.4283 - acc: 0.51 - ETA: 14s - loss: 1.4067 - acc: 0.52 - ETA: 14s - loss: 1.3878 - acc: 0.53 - ETA: 13s - loss: 1.3669 - acc: 0.53 - ETA: 13s - loss: 1.3423 - acc: 0.54 - ETA: 13s - loss: 1.3222 - acc: 0.55 - ETA: 12s - loss: 1.3035 - acc: 0.55 - ETA: 12s - loss: 1.2845 - acc: 0.56 - ETA: 12s - loss: 1.2685 - acc: 0.57 - ETA: 11s - loss: 1.2533 - acc: 0.57 - ETA: 11s - loss: 1.2368 - acc: 0.58 - ETA: 11s - loss: 1.2147 - acc: 0.58 - ETA: 10s - loss: 1.1999 - acc: 0.59 - ETA: 10s - loss: 1.1806 - acc: 0.59 - ETA: 10s - loss: 1.1661 - acc: 0.60 - ETA: 9s - loss: 1.1511 - acc: 0.6092 - ETA: 9s - loss: 1.1396 - acc: 0.613 - ETA: 9s - loss: 1.1274 - acc: 0.617 - ETA: 9s - loss: 1.1135 - acc: 0.621 - ETA: 9s - loss: 1.1023 - acc: 0.625 - ETA: 8s - loss: 1.0920 - acc: 0.629 - ETA: 8s - loss: 1.0781 - acc: 0.634 - ETA: 8s - loss: 1.0660 - acc: 0.638 - ETA: 8s - loss: 1.0549 - acc: 0.641 - ETA: 8s - loss: 1.0430 - acc: 0.645 - ETA: 7s - loss: 1.0285 - acc: 0.650 - ETA: 7s - loss: 1.0187 - acc: 0.654 - ETA: 7s - loss: 1.0048 - acc: 0.658 - ETA: 7s - loss: 0.9920 - acc: 0.663 - ETA: 6s - loss: 0.9831 - acc: 0.666 - ETA: 6s - loss: 0.9747 - acc: 0.669 - ETA: 6s - loss: 0.9668 - acc: 0.672 - ETA: 6s - loss: 0.9582 - acc: 0.674 - ETA: 6s - loss: 0.9497 - acc: 0.677 - ETA: 6s - loss: 0.9426 - acc: 0.680 - ETA: 5s - loss: 0.9314 - acc: 0.684 - ETA: 5s - loss: 0.9221 - acc: 0.687 - ETA: 5s - loss: 0.9142 - acc: 0.689 - ETA: 5s - loss: 0.9073 - acc: 0.692 - ETA: 5s - loss: 0.8987 - acc: 0.695 - ETA: 5s - loss: 0.8925 - acc: 0.697 - ETA: 5s - loss: 0.8854 - acc: 0.700 - ETA: 5s - loss: 0.8791 - acc: 0.702 - ETA: 4s - loss: 0.8715 - acc: 0.704 - ETA: 4s - loss: 0.8640 - acc: 0.707 - ETA: 4s - loss: 0.8571 - acc: 0.709 - ETA: 4s - loss: 0.8497 - acc: 0.711 - ETA: 4s - loss: 0.8431 - acc: 0.713 - ETA: 4s - loss: 0.8372 - acc: 0.715 - ETA: 4s - loss: 0.8301 - acc: 0.718 - ETA: 4s - loss: 0.8239 - acc: 0.720 - ETA: 3s - loss: 0.8187 - acc: 0.722 - ETA: 3s - loss: 0.8119 - acc: 0.724 - ETA: 3s - loss: 0.8036 - acc: 0.727 - ETA: 3s - loss: 0.7971 - acc: 0.729 - ETA: 3s - loss: 0.7913 - acc: 0.731 - ETA: 3s - loss: 0.7849 - acc: 0.733 - ETA: 3s - loss: 0.7800 - acc: 0.735 - ETA: 3s - loss: 0.7748 - acc: 0.737 - ETA: 3s - loss: 0.7702 - acc: 0.738 - ETA: 2s - loss: 0.7652 - acc: 0.740 - ETA: 2s - loss: 0.7584 - acc: 0.742 - ETA: 2s - loss: 0.7541 - acc: 0.744 - ETA: 2s - loss: 0.7497 - acc: 0.745 - ETA: 2s - loss: 0.7453 - acc: 0.747 - ETA: 2s - loss: 0.7408 - acc: 0.749 - ETA: 2s - loss: 0.7357 - acc: 0.750 - ETA: 2s - loss: 0.7315 - acc: 0.752 - ETA: 2s - loss: 0.7276 - acc: 0.753 - ETA: 2s - loss: 0.7228 - acc: 0.755 - ETA: 1s - loss: 0.7183 - acc: 0.757 - ETA: 1s - loss: 0.7143 - acc: 0.758 - ETA: 1s - loss: 0.7103 - acc: 0.759 - ETA: 1s - loss: 0.7063 - acc: 0.761 - ETA: 1s - loss: 0.7002 - acc: 0.763 - ETA: 1s - loss: 0.6963 - acc: 0.764 - ETA: 1s - loss: 0.6929 - acc: 0.765 - ETA: 1s - loss: 0.6887 - acc: 0.767 - ETA: 1s - loss: 0.6852 - acc: 0.768 - ETA: 1s - loss: 0.6810 - acc: 0.769 - ETA: 0s - loss: 0.6757 - acc: 0.771 - ETA: 0s - loss: 0.6722 - acc: 0.772 - ETA: 0s - loss: 0.6681 - acc: 0.774 - ETA: 0s - loss: 0.6644 - acc: 0.775 - ETA: 0s - loss: 0.6612 - acc: 0.776 - ETA: 0s - loss: 0.6558 - acc: 0.778 - ETA: 0s - loss: 0.6526 - acc: 0.779 - ETA: 0s - loss: 0.6493 - acc: 0.780 - ETA: 0s - loss: 0.6448 - acc: 0.782 - ETA: 0s - loss: 0.6414 - acc: 0.783 - ETA: 0s - loss: 0.6378 - acc: 0.784 - ETA: 0s - loss: 0.6345 - acc: 0.786 - 11s 216us/sample - loss: 0.6338 - acc: 0.7862 - val_loss: 6.0642 - val_acc: 0.1281\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.014430626211475785.\n",
      "Epoch 2/20\n",
      "49740/49740 [==============================] - ETA: 6s - loss: 0.2697 - acc: 0.914 - ETA: 7s - loss: 0.2681 - acc: 0.918 - ETA: 6s - loss: 0.2319 - acc: 0.927 - ETA: 6s - loss: 0.2316 - acc: 0.928 - ETA: 6s - loss: 0.2137 - acc: 0.933 - ETA: 6s - loss: 0.2156 - acc: 0.932 - ETA: 6s - loss: 0.2111 - acc: 0.933 - ETA: 6s - loss: 0.2119 - acc: 0.930 - ETA: 6s - loss: 0.2065 - acc: 0.932 - ETA: 6s - loss: 0.1976 - acc: 0.935 - ETA: 6s - loss: 0.2000 - acc: 0.935 - ETA: 6s - loss: 0.2003 - acc: 0.935 - ETA: 6s - loss: 0.1975 - acc: 0.935 - ETA: 6s - loss: 0.1956 - acc: 0.936 - ETA: 5s - loss: 0.1922 - acc: 0.938 - ETA: 5s - loss: 0.1903 - acc: 0.939 - ETA: 5s - loss: 0.1892 - acc: 0.939 - ETA: 5s - loss: 0.1873 - acc: 0.940 - ETA: 5s - loss: 0.1902 - acc: 0.940 - ETA: 5s - loss: 0.1904 - acc: 0.941 - ETA: 5s - loss: 0.1909 - acc: 0.941 - ETA: 5s - loss: 0.1887 - acc: 0.941 - ETA: 5s - loss: 0.1877 - acc: 0.942 - ETA: 5s - loss: 0.1869 - acc: 0.942 - ETA: 5s - loss: 0.1888 - acc: 0.941 - ETA: 5s - loss: 0.1864 - acc: 0.942 - ETA: 5s - loss: 0.1838 - acc: 0.943 - ETA: 5s - loss: 0.1823 - acc: 0.944 - ETA: 5s - loss: 0.1819 - acc: 0.944 - ETA: 5s - loss: 0.1824 - acc: 0.944 - ETA: 4s - loss: 0.1813 - acc: 0.944 - ETA: 4s - loss: 0.1811 - acc: 0.944 - ETA: 4s - loss: 0.1811 - acc: 0.944 - ETA: 4s - loss: 0.1805 - acc: 0.944 - ETA: 4s - loss: 0.1795 - acc: 0.945 - ETA: 4s - loss: 0.1795 - acc: 0.945 - ETA: 4s - loss: 0.1797 - acc: 0.945 - ETA: 4s - loss: 0.1788 - acc: 0.945 - ETA: 4s - loss: 0.1787 - acc: 0.945 - ETA: 4s - loss: 0.1766 - acc: 0.945 - ETA: 4s - loss: 0.1777 - acc: 0.945 - ETA: 4s - loss: 0.1768 - acc: 0.945 - ETA: 4s - loss: 0.1755 - acc: 0.945 - ETA: 4s - loss: 0.1747 - acc: 0.946 - ETA: 4s - loss: 0.1745 - acc: 0.945 - ETA: 4s - loss: 0.1742 - acc: 0.946 - ETA: 4s - loss: 0.1748 - acc: 0.945 - ETA: 4s - loss: 0.1738 - acc: 0.946 - ETA: 3s - loss: 0.1729 - acc: 0.946 - ETA: 3s - loss: 0.1727 - acc: 0.946 - ETA: 3s - loss: 0.1720 - acc: 0.946 - ETA: 3s - loss: 0.1721 - acc: 0.946 - ETA: 3s - loss: 0.1716 - acc: 0.946 - ETA: 3s - loss: 0.1716 - acc: 0.946 - ETA: 3s - loss: 0.1710 - acc: 0.946 - ETA: 3s - loss: 0.1706 - acc: 0.946 - ETA: 3s - loss: 0.1701 - acc: 0.947 - ETA: 3s - loss: 0.1711 - acc: 0.946 - ETA: 3s - loss: 0.1708 - acc: 0.947 - ETA: 3s - loss: 0.1697 - acc: 0.947 - ETA: 3s - loss: 0.1690 - acc: 0.947 - ETA: 3s - loss: 0.1682 - acc: 0.947 - ETA: 3s - loss: 0.1677 - acc: 0.947 - ETA: 3s - loss: 0.1674 - acc: 0.947 - ETA: 3s - loss: 0.1683 - acc: 0.947 - ETA: 3s - loss: 0.1683 - acc: 0.947 - ETA: 2s - loss: 0.1687 - acc: 0.947 - ETA: 2s - loss: 0.1682 - acc: 0.947 - ETA: 2s - loss: 0.1675 - acc: 0.947 - ETA: 2s - loss: 0.1670 - acc: 0.947 - ETA: 2s - loss: 0.1672 - acc: 0.947 - ETA: 2s - loss: 0.1668 - acc: 0.947 - ETA: 2s - loss: 0.1660 - acc: 0.948 - ETA: 2s - loss: 0.1656 - acc: 0.948 - ETA: 2s - loss: 0.1656 - acc: 0.948 - ETA: 2s - loss: 0.1650 - acc: 0.948 - ETA: 2s - loss: 0.1647 - acc: 0.948 - ETA: 2s - loss: 0.1643 - acc: 0.948 - ETA: 2s - loss: 0.1638 - acc: 0.948 - ETA: 2s - loss: 0.1632 - acc: 0.948 - ETA: 2s - loss: 0.1637 - acc: 0.948 - ETA: 2s - loss: 0.1643 - acc: 0.948 - ETA: 2s - loss: 0.1645 - acc: 0.948 - ETA: 2s - loss: 0.1642 - acc: 0.948 - ETA: 2s - loss: 0.1646 - acc: 0.948 - ETA: 2s - loss: 0.1650 - acc: 0.948 - ETA: 1s - loss: 0.1656 - acc: 0.948 - ETA: 1s - loss: 0.1652 - acc: 0.948 - ETA: 1s - loss: 0.1653 - acc: 0.948 - ETA: 1s - loss: 0.1651 - acc: 0.948 - ETA: 1s - loss: 0.1649 - acc: 0.948 - ETA: 1s - loss: 0.1647 - acc: 0.948 - ETA: 1s - loss: 0.1641 - acc: 0.948 - ETA: 1s - loss: 0.1641 - acc: 0.948 - ETA: 1s - loss: 0.1644 - acc: 0.948 - ETA: 1s - loss: 0.1640 - acc: 0.948 - ETA: 1s - loss: 0.1643 - acc: 0.948 - ETA: 1s - loss: 0.1641 - acc: 0.948 - ETA: 1s - loss: 0.1640 - acc: 0.948 - ETA: 1s - loss: 0.1637 - acc: 0.948 - ETA: 1s - loss: 0.1642 - acc: 0.948 - ETA: 1s - loss: 0.1642 - acc: 0.948 - ETA: 1s - loss: 0.1639 - acc: 0.948 - ETA: 1s - loss: 0.1637 - acc: 0.948 - ETA: 0s - loss: 0.1637 - acc: 0.949 - ETA: 0s - loss: 0.1634 - acc: 0.949 - ETA: 0s - loss: 0.1636 - acc: 0.949 - ETA: 0s - loss: 0.1633 - acc: 0.949 - ETA: 0s - loss: 0.1629 - acc: 0.949 - ETA: 0s - loss: 0.1627 - acc: 0.949 - ETA: 0s - loss: 0.1620 - acc: 0.949 - ETA: 0s - loss: 0.1617 - acc: 0.949 - ETA: 0s - loss: 0.1614 - acc: 0.949 - ETA: 0s - loss: 0.1612 - acc: 0.949 - ETA: 0s - loss: 0.1608 - acc: 0.950 - ETA: 0s - loss: 0.1603 - acc: 0.950 - ETA: 0s - loss: 0.1602 - acc: 0.950 - ETA: 0s - loss: 0.1596 - acc: 0.950 - ETA: 0s - loss: 0.1596 - acc: 0.950 - ETA: 0s - loss: 0.1594 - acc: 0.950 - ETA: 0s - loss: 0.1594 - acc: 0.950 - ETA: 0s - loss: 0.1593 - acc: 0.950 - 7s 136us/sample - loss: 0.1591 - acc: 0.9506 - val_loss: 14.4625 - val_acc: 0.1015\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.01036834238065184.\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49740/49740 [==============================] - ETA: 6s - loss: 0.3002 - acc: 0.937 - ETA: 6s - loss: 0.1693 - acc: 0.945 - ETA: 6s - loss: 0.1484 - acc: 0.950 - ETA: 6s - loss: 0.1372 - acc: 0.957 - ETA: 6s - loss: 0.1337 - acc: 0.957 - ETA: 6s - loss: 0.1300 - acc: 0.956 - ETA: 6s - loss: 0.1337 - acc: 0.956 - ETA: 6s - loss: 0.1308 - acc: 0.957 - ETA: 6s - loss: 0.1264 - acc: 0.957 - ETA: 6s - loss: 0.1287 - acc: 0.958 - ETA: 6s - loss: 0.1291 - acc: 0.958 - ETA: 6s - loss: 0.1289 - acc: 0.957 - ETA: 6s - loss: 0.1273 - acc: 0.957 - ETA: 6s - loss: 0.1251 - acc: 0.958 - ETA: 5s - loss: 0.1225 - acc: 0.959 - ETA: 5s - loss: 0.1200 - acc: 0.960 - ETA: 5s - loss: 0.1182 - acc: 0.961 - ETA: 5s - loss: 0.1178 - acc: 0.961 - ETA: 5s - loss: 0.1162 - acc: 0.961 - ETA: 5s - loss: 0.1170 - acc: 0.961 - ETA: 5s - loss: 0.1171 - acc: 0.961 - ETA: 5s - loss: 0.1150 - acc: 0.961 - ETA: 5s - loss: 0.1138 - acc: 0.961 - ETA: 5s - loss: 0.1154 - acc: 0.961 - ETA: 5s - loss: 0.1156 - acc: 0.961 - ETA: 5s - loss: 0.1154 - acc: 0.962 - ETA: 5s - loss: 0.1149 - acc: 0.962 - ETA: 5s - loss: 0.1164 - acc: 0.962 - ETA: 5s - loss: 0.1177 - acc: 0.961 - ETA: 5s - loss: 0.1176 - acc: 0.962 - ETA: 5s - loss: 0.1170 - acc: 0.962 - ETA: 4s - loss: 0.1154 - acc: 0.963 - ETA: 4s - loss: 0.1144 - acc: 0.963 - ETA: 4s - loss: 0.1161 - acc: 0.963 - ETA: 4s - loss: 0.1158 - acc: 0.963 - ETA: 4s - loss: 0.1148 - acc: 0.963 - ETA: 4s - loss: 0.1133 - acc: 0.964 - ETA: 4s - loss: 0.1128 - acc: 0.964 - ETA: 4s - loss: 0.1124 - acc: 0.964 - ETA: 4s - loss: 0.1135 - acc: 0.964 - ETA: 4s - loss: 0.1124 - acc: 0.964 - ETA: 4s - loss: 0.1114 - acc: 0.964 - ETA: 4s - loss: 0.1117 - acc: 0.964 - ETA: 4s - loss: 0.1113 - acc: 0.964 - ETA: 4s - loss: 0.1123 - acc: 0.964 - ETA: 4s - loss: 0.1123 - acc: 0.964 - ETA: 4s - loss: 0.1112 - acc: 0.964 - ETA: 4s - loss: 0.1102 - acc: 0.965 - ETA: 4s - loss: 0.1095 - acc: 0.965 - ETA: 3s - loss: 0.1095 - acc: 0.965 - ETA: 3s - loss: 0.1101 - acc: 0.965 - ETA: 3s - loss: 0.1104 - acc: 0.964 - ETA: 3s - loss: 0.1107 - acc: 0.964 - ETA: 3s - loss: 0.1103 - acc: 0.964 - ETA: 3s - loss: 0.1097 - acc: 0.964 - ETA: 3s - loss: 0.1089 - acc: 0.965 - ETA: 3s - loss: 0.1090 - acc: 0.965 - ETA: 3s - loss: 0.1092 - acc: 0.965 - ETA: 3s - loss: 0.1087 - acc: 0.965 - ETA: 3s - loss: 0.1089 - acc: 0.965 - ETA: 3s - loss: 0.1081 - acc: 0.965 - ETA: 3s - loss: 0.1075 - acc: 0.965 - ETA: 3s - loss: 0.1081 - acc: 0.965 - ETA: 3s - loss: 0.1083 - acc: 0.965 - ETA: 3s - loss: 0.1080 - acc: 0.966 - ETA: 3s - loss: 0.1076 - acc: 0.966 - ETA: 3s - loss: 0.1077 - acc: 0.966 - ETA: 2s - loss: 0.1074 - acc: 0.966 - ETA: 2s - loss: 0.1068 - acc: 0.966 - ETA: 2s - loss: 0.1063 - acc: 0.966 - ETA: 2s - loss: 0.1070 - acc: 0.966 - ETA: 2s - loss: 0.1067 - acc: 0.966 - ETA: 2s - loss: 0.1065 - acc: 0.966 - ETA: 2s - loss: 0.1072 - acc: 0.966 - ETA: 2s - loss: 0.1075 - acc: 0.966 - ETA: 2s - loss: 0.1076 - acc: 0.966 - ETA: 2s - loss: 0.1073 - acc: 0.966 - ETA: 2s - loss: 0.1069 - acc: 0.966 - ETA: 2s - loss: 0.1070 - acc: 0.966 - ETA: 2s - loss: 0.1075 - acc: 0.965 - ETA: 2s - loss: 0.1068 - acc: 0.966 - ETA: 2s - loss: 0.1067 - acc: 0.966 - ETA: 2s - loss: 0.1076 - acc: 0.965 - ETA: 2s - loss: 0.1071 - acc: 0.966 - ETA: 2s - loss: 0.1074 - acc: 0.965 - ETA: 1s - loss: 0.1073 - acc: 0.965 - ETA: 1s - loss: 0.1078 - acc: 0.965 - ETA: 1s - loss: 0.1080 - acc: 0.965 - ETA: 1s - loss: 0.1082 - acc: 0.965 - ETA: 1s - loss: 0.1080 - acc: 0.965 - ETA: 1s - loss: 0.1076 - acc: 0.965 - ETA: 1s - loss: 0.1081 - acc: 0.965 - ETA: 1s - loss: 0.1077 - acc: 0.965 - ETA: 1s - loss: 0.1073 - acc: 0.965 - ETA: 1s - loss: 0.1071 - acc: 0.966 - ETA: 1s - loss: 0.1072 - acc: 0.965 - ETA: 1s - loss: 0.1074 - acc: 0.965 - ETA: 1s - loss: 0.1073 - acc: 0.965 - ETA: 1s - loss: 0.1070 - acc: 0.965 - ETA: 1s - loss: 0.1066 - acc: 0.965 - ETA: 1s - loss: 0.1062 - acc: 0.966 - ETA: 1s - loss: 0.1066 - acc: 0.965 - ETA: 1s - loss: 0.1063 - acc: 0.966 - ETA: 1s - loss: 0.1060 - acc: 0.966 - ETA: 0s - loss: 0.1057 - acc: 0.966 - ETA: 0s - loss: 0.1056 - acc: 0.966 - ETA: 0s - loss: 0.1060 - acc: 0.965 - ETA: 0s - loss: 0.1058 - acc: 0.966 - ETA: 0s - loss: 0.1059 - acc: 0.966 - ETA: 0s - loss: 0.1068 - acc: 0.965 - ETA: 0s - loss: 0.1070 - acc: 0.965 - ETA: 0s - loss: 0.1068 - acc: 0.965 - ETA: 0s - loss: 0.1070 - acc: 0.965 - ETA: 0s - loss: 0.1070 - acc: 0.965 - ETA: 0s - loss: 0.1069 - acc: 0.965 - ETA: 0s - loss: 0.1068 - acc: 0.965 - ETA: 0s - loss: 0.1069 - acc: 0.965 - ETA: 0s - loss: 0.1067 - acc: 0.965 - ETA: 0s - loss: 0.1068 - acc: 0.965 - ETA: 0s - loss: 0.1066 - acc: 0.965 - ETA: 0s - loss: 0.1063 - acc: 0.966 - ETA: 0s - loss: 0.1065 - acc: 0.966 - 7s 136us/sample - loss: 0.1066 - acc: 0.9661 - val_loss: 14.0590 - val_acc: 0.1015\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.007457588823428847.\n",
      "Epoch 4/20\n",
      "49740/49740 [==============================] - ETA: 6s - loss: 0.0858 - acc: 0.968 - ETA: 6s - loss: 0.0746 - acc: 0.978 - ETA: 6s - loss: 0.0877 - acc: 0.972 - ETA: 6s - loss: 0.0934 - acc: 0.971 - ETA: 6s - loss: 0.0844 - acc: 0.975 - ETA: 6s - loss: 0.0773 - acc: 0.978 - ETA: 6s - loss: 0.0801 - acc: 0.977 - ETA: 6s - loss: 0.0812 - acc: 0.976 - ETA: 6s - loss: 0.0776 - acc: 0.977 - ETA: 6s - loss: 0.0739 - acc: 0.978 - ETA: 6s - loss: 0.0737 - acc: 0.978 - ETA: 5s - loss: 0.0717 - acc: 0.978 - ETA: 5s - loss: 0.0729 - acc: 0.978 - ETA: 5s - loss: 0.0727 - acc: 0.977 - ETA: 5s - loss: 0.0740 - acc: 0.976 - ETA: 5s - loss: 0.0749 - acc: 0.976 - ETA: 5s - loss: 0.0727 - acc: 0.977 - ETA: 5s - loss: 0.0727 - acc: 0.977 - ETA: 5s - loss: 0.0739 - acc: 0.977 - ETA: 5s - loss: 0.0739 - acc: 0.977 - ETA: 5s - loss: 0.0746 - acc: 0.977 - ETA: 5s - loss: 0.0748 - acc: 0.977 - ETA: 5s - loss: 0.0750 - acc: 0.977 - ETA: 5s - loss: 0.0744 - acc: 0.977 - ETA: 5s - loss: 0.0765 - acc: 0.976 - ETA: 5s - loss: 0.0759 - acc: 0.976 - ETA: 5s - loss: 0.0766 - acc: 0.976 - ETA: 5s - loss: 0.0773 - acc: 0.976 - ETA: 4s - loss: 0.0780 - acc: 0.975 - ETA: 4s - loss: 0.0776 - acc: 0.976 - ETA: 4s - loss: 0.0767 - acc: 0.976 - ETA: 4s - loss: 0.0763 - acc: 0.976 - ETA: 4s - loss: 0.0764 - acc: 0.976 - ETA: 4s - loss: 0.0764 - acc: 0.976 - ETA: 4s - loss: 0.0756 - acc: 0.976 - ETA: 4s - loss: 0.0752 - acc: 0.976 - ETA: 4s - loss: 0.0753 - acc: 0.976 - ETA: 4s - loss: 0.0754 - acc: 0.976 - ETA: 4s - loss: 0.0762 - acc: 0.976 - ETA: 4s - loss: 0.0763 - acc: 0.975 - ETA: 4s - loss: 0.0764 - acc: 0.975 - ETA: 4s - loss: 0.0760 - acc: 0.976 - ETA: 4s - loss: 0.0753 - acc: 0.976 - ETA: 4s - loss: 0.0758 - acc: 0.976 - ETA: 4s - loss: 0.0762 - acc: 0.975 - ETA: 4s - loss: 0.0755 - acc: 0.976 - ETA: 3s - loss: 0.0760 - acc: 0.975 - ETA: 3s - loss: 0.0756 - acc: 0.976 - ETA: 3s - loss: 0.0753 - acc: 0.976 - ETA: 3s - loss: 0.0760 - acc: 0.976 - ETA: 3s - loss: 0.0763 - acc: 0.975 - ETA: 3s - loss: 0.0762 - acc: 0.976 - ETA: 3s - loss: 0.0776 - acc: 0.975 - ETA: 3s - loss: 0.0778 - acc: 0.975 - ETA: 3s - loss: 0.0778 - acc: 0.975 - ETA: 3s - loss: 0.0778 - acc: 0.975 - ETA: 3s - loss: 0.0774 - acc: 0.975 - ETA: 3s - loss: 0.0772 - acc: 0.975 - ETA: 3s - loss: 0.0776 - acc: 0.975 - ETA: 3s - loss: 0.0773 - acc: 0.975 - ETA: 3s - loss: 0.0773 - acc: 0.975 - ETA: 3s - loss: 0.0775 - acc: 0.975 - ETA: 3s - loss: 0.0768 - acc: 0.975 - ETA: 3s - loss: 0.0764 - acc: 0.975 - ETA: 3s - loss: 0.0761 - acc: 0.975 - ETA: 2s - loss: 0.0763 - acc: 0.975 - ETA: 2s - loss: 0.0763 - acc: 0.975 - ETA: 2s - loss: 0.0759 - acc: 0.975 - ETA: 2s - loss: 0.0758 - acc: 0.975 - ETA: 2s - loss: 0.0754 - acc: 0.976 - ETA: 2s - loss: 0.0753 - acc: 0.976 - ETA: 2s - loss: 0.0755 - acc: 0.976 - ETA: 2s - loss: 0.0761 - acc: 0.976 - ETA: 2s - loss: 0.0767 - acc: 0.975 - ETA: 2s - loss: 0.0768 - acc: 0.975 - ETA: 2s - loss: 0.0771 - acc: 0.975 - ETA: 2s - loss: 0.0770 - acc: 0.975 - ETA: 2s - loss: 0.0770 - acc: 0.975 - ETA: 2s - loss: 0.0776 - acc: 0.975 - ETA: 2s - loss: 0.0778 - acc: 0.975 - ETA: 2s - loss: 0.0777 - acc: 0.975 - ETA: 2s - loss: 0.0775 - acc: 0.975 - ETA: 2s - loss: 0.0774 - acc: 0.975 - ETA: 2s - loss: 0.0779 - acc: 0.975 - ETA: 1s - loss: 0.0781 - acc: 0.975 - ETA: 1s - loss: 0.0782 - acc: 0.975 - ETA: 1s - loss: 0.0782 - acc: 0.975 - ETA: 1s - loss: 0.0784 - acc: 0.974 - ETA: 1s - loss: 0.0784 - acc: 0.974 - ETA: 1s - loss: 0.0784 - acc: 0.975 - ETA: 1s - loss: 0.0783 - acc: 0.975 - ETA: 1s - loss: 0.0782 - acc: 0.975 - ETA: 1s - loss: 0.0782 - acc: 0.975 - ETA: 1s - loss: 0.0783 - acc: 0.975 - ETA: 1s - loss: 0.0782 - acc: 0.975 - ETA: 1s - loss: 0.0783 - acc: 0.975 - ETA: 1s - loss: 0.0782 - acc: 0.975 - ETA: 1s - loss: 0.0782 - acc: 0.975 - ETA: 1s - loss: 0.0779 - acc: 0.975 - ETA: 1s - loss: 0.0778 - acc: 0.975 - ETA: 1s - loss: 0.0776 - acc: 0.975 - ETA: 1s - loss: 0.0774 - acc: 0.975 - ETA: 1s - loss: 0.0775 - acc: 0.975 - ETA: 0s - loss: 0.0773 - acc: 0.975 - ETA: 0s - loss: 0.0772 - acc: 0.975 - ETA: 0s - loss: 0.0769 - acc: 0.975 - ETA: 0s - loss: 0.0772 - acc: 0.975 - ETA: 0s - loss: 0.0777 - acc: 0.975 - ETA: 0s - loss: 0.0780 - acc: 0.975 - ETA: 0s - loss: 0.0780 - acc: 0.975 - ETA: 0s - loss: 0.0779 - acc: 0.975 - ETA: 0s - loss: 0.0780 - acc: 0.975 - ETA: 0s - loss: 0.0779 - acc: 0.975 - ETA: 0s - loss: 0.0781 - acc: 0.975 - ETA: 0s - loss: 0.0779 - acc: 0.975 - ETA: 0s - loss: 0.0774 - acc: 0.975 - ETA: 0s - loss: 0.0774 - acc: 0.975 - ETA: 0s - loss: 0.0777 - acc: 0.975 - ETA: 0s - loss: 0.0774 - acc: 0.975 - ETA: 0s - loss: 0.0772 - acc: 0.975 - ETA: 0s - loss: 0.0777 - acc: 0.975 - 7s 136us/sample - loss: 0.0777 - acc: 0.9753 - val_loss: 3.7443 - val_acc: 0.3496\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.005371942762314537.\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49740/49740 [==============================] - ETA: 6s - loss: 0.0649 - acc: 0.976 - ETA: 6s - loss: 0.0617 - acc: 0.976 - ETA: 6s - loss: 0.0634 - acc: 0.978 - ETA: 6s - loss: 0.0660 - acc: 0.978 - ETA: 6s - loss: 0.0688 - acc: 0.979 - ETA: 6s - loss: 0.0688 - acc: 0.979 - ETA: 6s - loss: 0.0659 - acc: 0.979 - ETA: 6s - loss: 0.0657 - acc: 0.979 - ETA: 6s - loss: 0.0678 - acc: 0.978 - ETA: 6s - loss: 0.0679 - acc: 0.978 - ETA: 6s - loss: 0.0648 - acc: 0.979 - ETA: 6s - loss: 0.0628 - acc: 0.979 - ETA: 6s - loss: 0.0629 - acc: 0.979 - ETA: 5s - loss: 0.0626 - acc: 0.980 - ETA: 5s - loss: 0.0601 - acc: 0.981 - ETA: 5s - loss: 0.0606 - acc: 0.981 - ETA: 5s - loss: 0.0621 - acc: 0.980 - ETA: 5s - loss: 0.0621 - acc: 0.980 - ETA: 5s - loss: 0.0617 - acc: 0.981 - ETA: 5s - loss: 0.0629 - acc: 0.981 - ETA: 5s - loss: 0.0623 - acc: 0.981 - ETA: 5s - loss: 0.0645 - acc: 0.980 - ETA: 5s - loss: 0.0632 - acc: 0.981 - ETA: 5s - loss: 0.0627 - acc: 0.981 - ETA: 5s - loss: 0.0647 - acc: 0.980 - ETA: 5s - loss: 0.0631 - acc: 0.981 - ETA: 5s - loss: 0.0625 - acc: 0.981 - ETA: 5s - loss: 0.0625 - acc: 0.981 - ETA: 5s - loss: 0.0625 - acc: 0.981 - ETA: 5s - loss: 0.0614 - acc: 0.981 - ETA: 5s - loss: 0.0617 - acc: 0.981 - ETA: 4s - loss: 0.0608 - acc: 0.981 - ETA: 4s - loss: 0.0606 - acc: 0.981 - ETA: 4s - loss: 0.0611 - acc: 0.981 - ETA: 4s - loss: 0.0607 - acc: 0.981 - ETA: 4s - loss: 0.0603 - acc: 0.981 - ETA: 4s - loss: 0.0609 - acc: 0.981 - ETA: 4s - loss: 0.0610 - acc: 0.981 - ETA: 4s - loss: 0.0615 - acc: 0.981 - ETA: 4s - loss: 0.0608 - acc: 0.981 - ETA: 4s - loss: 0.0609 - acc: 0.981 - ETA: 4s - loss: 0.0610 - acc: 0.981 - ETA: 4s - loss: 0.0612 - acc: 0.981 - ETA: 4s - loss: 0.0605 - acc: 0.981 - ETA: 4s - loss: 0.0615 - acc: 0.981 - ETA: 4s - loss: 0.0611 - acc: 0.981 - ETA: 4s - loss: 0.0611 - acc: 0.981 - ETA: 4s - loss: 0.0606 - acc: 0.981 - ETA: 4s - loss: 0.0607 - acc: 0.981 - ETA: 4s - loss: 0.0612 - acc: 0.981 - ETA: 3s - loss: 0.0614 - acc: 0.981 - ETA: 3s - loss: 0.0611 - acc: 0.981 - ETA: 3s - loss: 0.0607 - acc: 0.981 - ETA: 3s - loss: 0.0604 - acc: 0.981 - ETA: 3s - loss: 0.0609 - acc: 0.981 - ETA: 3s - loss: 0.0609 - acc: 0.981 - ETA: 3s - loss: 0.0611 - acc: 0.981 - ETA: 3s - loss: 0.0609 - acc: 0.981 - ETA: 3s - loss: 0.0612 - acc: 0.981 - ETA: 3s - loss: 0.0614 - acc: 0.981 - ETA: 3s - loss: 0.0616 - acc: 0.981 - ETA: 3s - loss: 0.0621 - acc: 0.981 - ETA: 3s - loss: 0.0616 - acc: 0.981 - ETA: 3s - loss: 0.0616 - acc: 0.981 - ETA: 3s - loss: 0.0615 - acc: 0.981 - ETA: 3s - loss: 0.0614 - acc: 0.981 - ETA: 3s - loss: 0.0616 - acc: 0.981 - ETA: 3s - loss: 0.0616 - acc: 0.981 - ETA: 3s - loss: 0.0622 - acc: 0.981 - ETA: 2s - loss: 0.0620 - acc: 0.981 - ETA: 2s - loss: 0.0621 - acc: 0.981 - ETA: 2s - loss: 0.0620 - acc: 0.981 - ETA: 2s - loss: 0.0619 - acc: 0.980 - ETA: 2s - loss: 0.0620 - acc: 0.980 - ETA: 2s - loss: 0.0619 - acc: 0.980 - ETA: 2s - loss: 0.0620 - acc: 0.980 - ETA: 2s - loss: 0.0617 - acc: 0.980 - ETA: 2s - loss: 0.0615 - acc: 0.980 - ETA: 2s - loss: 0.0616 - acc: 0.980 - ETA: 2s - loss: 0.0622 - acc: 0.980 - ETA: 2s - loss: 0.0624 - acc: 0.980 - ETA: 2s - loss: 0.0622 - acc: 0.980 - ETA: 2s - loss: 0.0626 - acc: 0.980 - ETA: 2s - loss: 0.0625 - acc: 0.980 - ETA: 2s - loss: 0.0622 - acc: 0.980 - ETA: 2s - loss: 0.0623 - acc: 0.980 - ETA: 2s - loss: 0.0624 - acc: 0.980 - ETA: 2s - loss: 0.0623 - acc: 0.980 - ETA: 1s - loss: 0.0625 - acc: 0.980 - ETA: 1s - loss: 0.0631 - acc: 0.980 - ETA: 1s - loss: 0.0628 - acc: 0.980 - ETA: 1s - loss: 0.0626 - acc: 0.980 - ETA: 1s - loss: 0.0629 - acc: 0.980 - ETA: 1s - loss: 0.0629 - acc: 0.980 - ETA: 1s - loss: 0.0630 - acc: 0.980 - ETA: 1s - loss: 0.0631 - acc: 0.980 - ETA: 1s - loss: 0.0630 - acc: 0.980 - ETA: 1s - loss: 0.0629 - acc: 0.980 - ETA: 1s - loss: 0.0632 - acc: 0.980 - ETA: 1s - loss: 0.0633 - acc: 0.980 - ETA: 1s - loss: 0.0630 - acc: 0.980 - ETA: 1s - loss: 0.0627 - acc: 0.980 - ETA: 1s - loss: 0.0627 - acc: 0.980 - ETA: 1s - loss: 0.0624 - acc: 0.980 - ETA: 1s - loss: 0.0621 - acc: 0.980 - ETA: 1s - loss: 0.0622 - acc: 0.980 - ETA: 1s - loss: 0.0619 - acc: 0.980 - ETA: 0s - loss: 0.0618 - acc: 0.980 - ETA: 0s - loss: 0.0617 - acc: 0.980 - ETA: 0s - loss: 0.0617 - acc: 0.980 - ETA: 0s - loss: 0.0617 - acc: 0.980 - ETA: 0s - loss: 0.0615 - acc: 0.981 - ETA: 0s - loss: 0.0614 - acc: 0.981 - ETA: 0s - loss: 0.0616 - acc: 0.981 - ETA: 0s - loss: 0.0616 - acc: 0.981 - ETA: 0s - loss: 0.0619 - acc: 0.981 - ETA: 0s - loss: 0.0619 - acc: 0.981 - ETA: 0s - loss: 0.0619 - acc: 0.981 - ETA: 0s - loss: 0.0617 - acc: 0.981 - ETA: 0s - loss: 0.0616 - acc: 0.981 - ETA: 0s - loss: 0.0617 - acc: 0.981 - ETA: 0s - loss: 0.0616 - acc: 0.981 - ETA: 0s - loss: 0.0617 - acc: 0.981 - ETA: 0s - loss: 0.0616 - acc: 0.981 - ETA: 0s - loss: 0.0615 - acc: 0.981 - 7s 139us/sample - loss: 0.0613 - acc: 0.9811 - val_loss: 9.5345 - val_acc: 0.2130\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0038775120567512366.\n",
      "Epoch 6/20\n",
      "49740/49740 [==============================] - ETA: 7s - loss: 0.0376 - acc: 0.984 - ETA: 6s - loss: 0.0493 - acc: 0.978 - ETA: 6s - loss: 0.0434 - acc: 0.982 - ETA: 6s - loss: 0.0553 - acc: 0.979 - ETA: 6s - loss: 0.0644 - acc: 0.979 - ETA: 6s - loss: 0.0613 - acc: 0.979 - ETA: 6s - loss: 0.0619 - acc: 0.980 - ETA: 6s - loss: 0.0595 - acc: 0.980 - ETA: 6s - loss: 0.0574 - acc: 0.980 - ETA: 6s - loss: 0.0560 - acc: 0.980 - ETA: 6s - loss: 0.0529 - acc: 0.981 - ETA: 5s - loss: 0.0498 - acc: 0.982 - ETA: 5s - loss: 0.0510 - acc: 0.983 - ETA: 5s - loss: 0.0523 - acc: 0.982 - ETA: 5s - loss: 0.0527 - acc: 0.982 - ETA: 5s - loss: 0.0534 - acc: 0.982 - ETA: 5s - loss: 0.0515 - acc: 0.983 - ETA: 5s - loss: 0.0506 - acc: 0.983 - ETA: 5s - loss: 0.0499 - acc: 0.983 - ETA: 5s - loss: 0.0501 - acc: 0.983 - ETA: 5s - loss: 0.0504 - acc: 0.983 - ETA: 5s - loss: 0.0496 - acc: 0.983 - ETA: 5s - loss: 0.0486 - acc: 0.983 - ETA: 5s - loss: 0.0483 - acc: 0.983 - ETA: 5s - loss: 0.0482 - acc: 0.984 - ETA: 5s - loss: 0.0487 - acc: 0.983 - ETA: 5s - loss: 0.0500 - acc: 0.983 - ETA: 5s - loss: 0.0492 - acc: 0.984 - ETA: 5s - loss: 0.0496 - acc: 0.983 - ETA: 5s - loss: 0.0493 - acc: 0.984 - ETA: 4s - loss: 0.0489 - acc: 0.984 - ETA: 4s - loss: 0.0487 - acc: 0.984 - ETA: 4s - loss: 0.0482 - acc: 0.984 - ETA: 4s - loss: 0.0480 - acc: 0.984 - ETA: 4s - loss: 0.0478 - acc: 0.984 - ETA: 4s - loss: 0.0478 - acc: 0.984 - ETA: 4s - loss: 0.0488 - acc: 0.984 - ETA: 4s - loss: 0.0482 - acc: 0.984 - ETA: 4s - loss: 0.0478 - acc: 0.985 - ETA: 4s - loss: 0.0487 - acc: 0.984 - ETA: 4s - loss: 0.0487 - acc: 0.984 - ETA: 4s - loss: 0.0482 - acc: 0.985 - ETA: 4s - loss: 0.0477 - acc: 0.985 - ETA: 4s - loss: 0.0478 - acc: 0.985 - ETA: 4s - loss: 0.0473 - acc: 0.985 - ETA: 4s - loss: 0.0469 - acc: 0.985 - ETA: 4s - loss: 0.0466 - acc: 0.985 - ETA: 4s - loss: 0.0467 - acc: 0.985 - ETA: 3s - loss: 0.0466 - acc: 0.985 - ETA: 3s - loss: 0.0460 - acc: 0.986 - ETA: 3s - loss: 0.0462 - acc: 0.986 - ETA: 3s - loss: 0.0460 - acc: 0.986 - ETA: 3s - loss: 0.0464 - acc: 0.985 - ETA: 3s - loss: 0.0461 - acc: 0.986 - ETA: 3s - loss: 0.0462 - acc: 0.986 - ETA: 3s - loss: 0.0461 - acc: 0.986 - ETA: 3s - loss: 0.0457 - acc: 0.986 - ETA: 3s - loss: 0.0458 - acc: 0.986 - ETA: 3s - loss: 0.0458 - acc: 0.986 - ETA: 3s - loss: 0.0456 - acc: 0.986 - ETA: 3s - loss: 0.0453 - acc: 0.986 - ETA: 3s - loss: 0.0453 - acc: 0.986 - ETA: 3s - loss: 0.0453 - acc: 0.986 - ETA: 3s - loss: 0.0453 - acc: 0.986 - ETA: 3s - loss: 0.0449 - acc: 0.986 - ETA: 3s - loss: 0.0455 - acc: 0.986 - ETA: 3s - loss: 0.0454 - acc: 0.986 - ETA: 2s - loss: 0.0455 - acc: 0.986 - ETA: 2s - loss: 0.0451 - acc: 0.986 - ETA: 2s - loss: 0.0449 - acc: 0.986 - ETA: 2s - loss: 0.0448 - acc: 0.986 - ETA: 2s - loss: 0.0450 - acc: 0.986 - ETA: 2s - loss: 0.0450 - acc: 0.986 - ETA: 2s - loss: 0.0451 - acc: 0.986 - ETA: 2s - loss: 0.0448 - acc: 0.986 - ETA: 2s - loss: 0.0447 - acc: 0.986 - ETA: 2s - loss: 0.0449 - acc: 0.986 - ETA: 2s - loss: 0.0448 - acc: 0.986 - ETA: 2s - loss: 0.0450 - acc: 0.985 - ETA: 2s - loss: 0.0452 - acc: 0.985 - ETA: 2s - loss: 0.0451 - acc: 0.986 - ETA: 2s - loss: 0.0452 - acc: 0.985 - ETA: 2s - loss: 0.0448 - acc: 0.986 - ETA: 2s - loss: 0.0447 - acc: 0.986 - ETA: 2s - loss: 0.0444 - acc: 0.986 - ETA: 1s - loss: 0.0445 - acc: 0.986 - ETA: 1s - loss: 0.0447 - acc: 0.986 - ETA: 1s - loss: 0.0446 - acc: 0.986 - ETA: 1s - loss: 0.0448 - acc: 0.986 - ETA: 1s - loss: 0.0446 - acc: 0.986 - ETA: 1s - loss: 0.0448 - acc: 0.986 - ETA: 1s - loss: 0.0447 - acc: 0.986 - ETA: 1s - loss: 0.0449 - acc: 0.986 - ETA: 1s - loss: 0.0453 - acc: 0.985 - ETA: 1s - loss: 0.0454 - acc: 0.985 - ETA: 1s - loss: 0.0454 - acc: 0.985 - ETA: 1s - loss: 0.0455 - acc: 0.985 - ETA: 1s - loss: 0.0457 - acc: 0.985 - ETA: 1s - loss: 0.0457 - acc: 0.985 - ETA: 1s - loss: 0.0458 - acc: 0.985 - ETA: 1s - loss: 0.0457 - acc: 0.985 - ETA: 1s - loss: 0.0455 - acc: 0.985 - ETA: 1s - loss: 0.0455 - acc: 0.985 - ETA: 1s - loss: 0.0456 - acc: 0.985 - ETA: 0s - loss: 0.0455 - acc: 0.985 - ETA: 0s - loss: 0.0455 - acc: 0.985 - ETA: 0s - loss: 0.0455 - acc: 0.985 - ETA: 0s - loss: 0.0458 - acc: 0.985 - ETA: 0s - loss: 0.0459 - acc: 0.985 - ETA: 0s - loss: 0.0461 - acc: 0.985 - ETA: 0s - loss: 0.0462 - acc: 0.985 - ETA: 0s - loss: 0.0463 - acc: 0.985 - ETA: 0s - loss: 0.0462 - acc: 0.985 - ETA: 0s - loss: 0.0463 - acc: 0.985 - ETA: 0s - loss: 0.0465 - acc: 0.985 - ETA: 0s - loss: 0.0464 - acc: 0.985 - ETA: 0s - loss: 0.0463 - acc: 0.985 - ETA: 0s - loss: 0.0463 - acc: 0.985 - ETA: 0s - loss: 0.0466 - acc: 0.985 - ETA: 0s - loss: 0.0466 - acc: 0.985 - ETA: 0s - loss: 0.0466 - acc: 0.985 - ETA: 0s - loss: 0.0467 - acc: 0.985 - ETA: 0s - loss: 0.0469 - acc: 0.985 - 7s 137us/sample - loss: 0.0469 - acc: 0.9851 - val_loss: 3.4627 - val_acc: 0.4775\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.002806705664732254.\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49740/49740 [==============================] - ETA: 6s - loss: 0.0805 - acc: 0.976 - ETA: 6s - loss: 0.0446 - acc: 0.985 - ETA: 6s - loss: 0.0428 - acc: 0.987 - ETA: 6s - loss: 0.0405 - acc: 0.987 - ETA: 6s - loss: 0.0424 - acc: 0.987 - ETA: 6s - loss: 0.0447 - acc: 0.985 - ETA: 6s - loss: 0.0431 - acc: 0.985 - ETA: 6s - loss: 0.0441 - acc: 0.985 - ETA: 6s - loss: 0.0432 - acc: 0.985 - ETA: 6s - loss: 0.0432 - acc: 0.985 - ETA: 6s - loss: 0.0431 - acc: 0.985 - ETA: 6s - loss: 0.0422 - acc: 0.985 - ETA: 5s - loss: 0.0420 - acc: 0.985 - ETA: 5s - loss: 0.0418 - acc: 0.985 - ETA: 5s - loss: 0.0427 - acc: 0.984 - ETA: 5s - loss: 0.0423 - acc: 0.985 - ETA: 5s - loss: 0.0416 - acc: 0.985 - ETA: 5s - loss: 0.0408 - acc: 0.985 - ETA: 5s - loss: 0.0418 - acc: 0.985 - ETA: 5s - loss: 0.0427 - acc: 0.985 - ETA: 5s - loss: 0.0444 - acc: 0.985 - ETA: 5s - loss: 0.0448 - acc: 0.985 - ETA: 5s - loss: 0.0441 - acc: 0.985 - ETA: 5s - loss: 0.0443 - acc: 0.985 - ETA: 5s - loss: 0.0437 - acc: 0.985 - ETA: 5s - loss: 0.0429 - acc: 0.986 - ETA: 5s - loss: 0.0422 - acc: 0.986 - ETA: 5s - loss: 0.0422 - acc: 0.986 - ETA: 5s - loss: 0.0424 - acc: 0.986 - ETA: 4s - loss: 0.0418 - acc: 0.986 - ETA: 4s - loss: 0.0417 - acc: 0.986 - ETA: 4s - loss: 0.0420 - acc: 0.986 - ETA: 4s - loss: 0.0417 - acc: 0.986 - ETA: 4s - loss: 0.0420 - acc: 0.986 - ETA: 4s - loss: 0.0418 - acc: 0.986 - ETA: 4s - loss: 0.0419 - acc: 0.986 - ETA: 4s - loss: 0.0417 - acc: 0.986 - ETA: 4s - loss: 0.0415 - acc: 0.986 - ETA: 4s - loss: 0.0410 - acc: 0.986 - ETA: 4s - loss: 0.0405 - acc: 0.986 - ETA: 4s - loss: 0.0403 - acc: 0.987 - ETA: 4s - loss: 0.0401 - acc: 0.987 - ETA: 4s - loss: 0.0401 - acc: 0.987 - ETA: 4s - loss: 0.0397 - acc: 0.987 - ETA: 4s - loss: 0.0394 - acc: 0.987 - ETA: 4s - loss: 0.0395 - acc: 0.987 - ETA: 4s - loss: 0.0396 - acc: 0.987 - ETA: 3s - loss: 0.0403 - acc: 0.987 - ETA: 3s - loss: 0.0400 - acc: 0.987 - ETA: 3s - loss: 0.0396 - acc: 0.987 - ETA: 3s - loss: 0.0395 - acc: 0.987 - ETA: 3s - loss: 0.0389 - acc: 0.988 - ETA: 3s - loss: 0.0390 - acc: 0.988 - ETA: 3s - loss: 0.0390 - acc: 0.988 - ETA: 3s - loss: 0.0388 - acc: 0.988 - ETA: 3s - loss: 0.0390 - acc: 0.988 - ETA: 3s - loss: 0.0387 - acc: 0.988 - ETA: 3s - loss: 0.0389 - acc: 0.987 - ETA: 3s - loss: 0.0391 - acc: 0.987 - ETA: 3s - loss: 0.0392 - acc: 0.987 - ETA: 3s - loss: 0.0392 - acc: 0.987 - ETA: 3s - loss: 0.0389 - acc: 0.987 - ETA: 3s - loss: 0.0387 - acc: 0.988 - ETA: 3s - loss: 0.0386 - acc: 0.988 - ETA: 3s - loss: 0.0386 - acc: 0.987 - ETA: 3s - loss: 0.0384 - acc: 0.988 - ETA: 2s - loss: 0.0382 - acc: 0.988 - ETA: 2s - loss: 0.0385 - acc: 0.988 - ETA: 2s - loss: 0.0383 - acc: 0.988 - ETA: 2s - loss: 0.0383 - acc: 0.988 - ETA: 2s - loss: 0.0387 - acc: 0.988 - ETA: 2s - loss: 0.0389 - acc: 0.988 - ETA: 2s - loss: 0.0391 - acc: 0.987 - ETA: 2s - loss: 0.0394 - acc: 0.987 - ETA: 2s - loss: 0.0392 - acc: 0.987 - ETA: 2s - loss: 0.0393 - acc: 0.987 - ETA: 2s - loss: 0.0392 - acc: 0.987 - ETA: 2s - loss: 0.0393 - acc: 0.987 - ETA: 2s - loss: 0.0393 - acc: 0.987 - ETA: 2s - loss: 0.0394 - acc: 0.987 - ETA: 2s - loss: 0.0395 - acc: 0.987 - ETA: 2s - loss: 0.0394 - acc: 0.987 - ETA: 2s - loss: 0.0393 - acc: 0.987 - ETA: 2s - loss: 0.0391 - acc: 0.987 - ETA: 1s - loss: 0.0390 - acc: 0.987 - ETA: 1s - loss: 0.0388 - acc: 0.987 - ETA: 1s - loss: 0.0387 - acc: 0.987 - ETA: 1s - loss: 0.0390 - acc: 0.987 - ETA: 1s - loss: 0.0391 - acc: 0.987 - ETA: 1s - loss: 0.0390 - acc: 0.987 - ETA: 1s - loss: 0.0392 - acc: 0.987 - ETA: 1s - loss: 0.0392 - acc: 0.987 - ETA: 1s - loss: 0.0395 - acc: 0.987 - ETA: 1s - loss: 0.0395 - acc: 0.987 - ETA: 1s - loss: 0.0394 - acc: 0.987 - ETA: 1s - loss: 0.0394 - acc: 0.987 - ETA: 1s - loss: 0.0393 - acc: 0.987 - ETA: 1s - loss: 0.0393 - acc: 0.987 - ETA: 1s - loss: 0.0392 - acc: 0.987 - ETA: 1s - loss: 0.0393 - acc: 0.987 - ETA: 1s - loss: 0.0395 - acc: 0.987 - ETA: 1s - loss: 0.0394 - acc: 0.987 - ETA: 1s - loss: 0.0396 - acc: 0.987 - ETA: 0s - loss: 0.0395 - acc: 0.987 - ETA: 0s - loss: 0.0394 - acc: 0.987 - ETA: 0s - loss: 0.0393 - acc: 0.987 - ETA: 0s - loss: 0.0397 - acc: 0.987 - ETA: 0s - loss: 0.0396 - acc: 0.987 - ETA: 0s - loss: 0.0396 - acc: 0.987 - ETA: 0s - loss: 0.0394 - acc: 0.987 - ETA: 0s - loss: 0.0397 - acc: 0.987 - ETA: 0s - loss: 0.0396 - acc: 0.987 - ETA: 0s - loss: 0.0396 - acc: 0.987 - ETA: 0s - loss: 0.0403 - acc: 0.987 - ETA: 0s - loss: 0.0403 - acc: 0.987 - ETA: 0s - loss: 0.0402 - acc: 0.987 - ETA: 0s - loss: 0.0402 - acc: 0.987 - ETA: 0s - loss: 0.0400 - acc: 0.987 - ETA: 0s - loss: 0.0399 - acc: 0.987 - ETA: 0s - loss: 0.0400 - acc: 0.987 - ETA: 0s - loss: 0.0401 - acc: 0.987 - 7s 136us/sample - loss: 0.0400 - acc: 0.9871 - val_loss: 2.8754 - val_acc: 0.4315\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.002039439357288101.\n",
      "Epoch 8/20\n",
      "49740/49740 [==============================] - ETA: 6s - loss: 0.0218 - acc: 0.992 - ETA: 6s - loss: 0.0221 - acc: 0.996 - ETA: 6s - loss: 0.0277 - acc: 0.993 - ETA: 6s - loss: 0.0287 - acc: 0.991 - ETA: 6s - loss: 0.0289 - acc: 0.990 - ETA: 6s - loss: 0.0314 - acc: 0.990 - ETA: 6s - loss: 0.0312 - acc: 0.989 - ETA: 6s - loss: 0.0310 - acc: 0.989 - ETA: 6s - loss: 0.0328 - acc: 0.989 - ETA: 6s - loss: 0.0323 - acc: 0.989 - ETA: 6s - loss: 0.0316 - acc: 0.990 - ETA: 6s - loss: 0.0310 - acc: 0.990 - ETA: 6s - loss: 0.0304 - acc: 0.990 - ETA: 6s - loss: 0.0303 - acc: 0.990 - ETA: 6s - loss: 0.0312 - acc: 0.990 - ETA: 5s - loss: 0.0308 - acc: 0.990 - ETA: 5s - loss: 0.0308 - acc: 0.990 - ETA: 5s - loss: 0.0318 - acc: 0.989 - ETA: 5s - loss: 0.0314 - acc: 0.990 - ETA: 5s - loss: 0.0310 - acc: 0.990 - ETA: 5s - loss: 0.0318 - acc: 0.989 - ETA: 5s - loss: 0.0328 - acc: 0.989 - ETA: 5s - loss: 0.0326 - acc: 0.989 - ETA: 5s - loss: 0.0326 - acc: 0.989 - ETA: 5s - loss: 0.0326 - acc: 0.989 - ETA: 5s - loss: 0.0320 - acc: 0.990 - ETA: 5s - loss: 0.0316 - acc: 0.990 - ETA: 5s - loss: 0.0312 - acc: 0.990 - ETA: 5s - loss: 0.0309 - acc: 0.990 - ETA: 5s - loss: 0.0311 - acc: 0.990 - ETA: 5s - loss: 0.0311 - acc: 0.990 - ETA: 5s - loss: 0.0312 - acc: 0.990 - ETA: 5s - loss: 0.0318 - acc: 0.990 - ETA: 5s - loss: 0.0333 - acc: 0.990 - ETA: 4s - loss: 0.0332 - acc: 0.990 - ETA: 4s - loss: 0.0337 - acc: 0.990 - ETA: 4s - loss: 0.0339 - acc: 0.989 - ETA: 4s - loss: 0.0340 - acc: 0.989 - ETA: 4s - loss: 0.0335 - acc: 0.989 - ETA: 4s - loss: 0.0345 - acc: 0.989 - ETA: 4s - loss: 0.0350 - acc: 0.989 - ETA: 4s - loss: 0.0352 - acc: 0.989 - ETA: 4s - loss: 0.0352 - acc: 0.989 - ETA: 4s - loss: 0.0350 - acc: 0.989 - ETA: 4s - loss: 0.0348 - acc: 0.989 - ETA: 4s - loss: 0.0353 - acc: 0.989 - ETA: 4s - loss: 0.0355 - acc: 0.989 - ETA: 4s - loss: 0.0356 - acc: 0.989 - ETA: 4s - loss: 0.0354 - acc: 0.989 - ETA: 4s - loss: 0.0359 - acc: 0.988 - ETA: 4s - loss: 0.0368 - acc: 0.988 - ETA: 4s - loss: 0.0373 - acc: 0.988 - ETA: 3s - loss: 0.0370 - acc: 0.988 - ETA: 3s - loss: 0.0371 - acc: 0.988 - ETA: 3s - loss: 0.0367 - acc: 0.988 - ETA: 3s - loss: 0.0368 - acc: 0.988 - ETA: 3s - loss: 0.0372 - acc: 0.988 - ETA: 3s - loss: 0.0370 - acc: 0.988 - ETA: 3s - loss: 0.0366 - acc: 0.988 - ETA: 3s - loss: 0.0363 - acc: 0.988 - ETA: 3s - loss: 0.0360 - acc: 0.988 - ETA: 3s - loss: 0.0358 - acc: 0.988 - ETA: 3s - loss: 0.0357 - acc: 0.988 - ETA: 3s - loss: 0.0359 - acc: 0.988 - ETA: 3s - loss: 0.0359 - acc: 0.988 - ETA: 3s - loss: 0.0361 - acc: 0.988 - ETA: 3s - loss: 0.0361 - acc: 0.988 - ETA: 3s - loss: 0.0361 - acc: 0.988 - ETA: 3s - loss: 0.0362 - acc: 0.988 - ETA: 2s - loss: 0.0360 - acc: 0.988 - ETA: 2s - loss: 0.0360 - acc: 0.988 - ETA: 2s - loss: 0.0361 - acc: 0.988 - ETA: 2s - loss: 0.0367 - acc: 0.988 - ETA: 2s - loss: 0.0367 - acc: 0.988 - ETA: 2s - loss: 0.0370 - acc: 0.988 - ETA: 2s - loss: 0.0370 - acc: 0.988 - ETA: 2s - loss: 0.0368 - acc: 0.988 - ETA: 2s - loss: 0.0368 - acc: 0.988 - ETA: 2s - loss: 0.0366 - acc: 0.988 - ETA: 2s - loss: 0.0367 - acc: 0.988 - ETA: 2s - loss: 0.0365 - acc: 0.988 - ETA: 2s - loss: 0.0362 - acc: 0.988 - ETA: 2s - loss: 0.0361 - acc: 0.988 - ETA: 2s - loss: 0.0362 - acc: 0.988 - ETA: 2s - loss: 0.0361 - acc: 0.988 - ETA: 2s - loss: 0.0360 - acc: 0.988 - ETA: 2s - loss: 0.0360 - acc: 0.988 - ETA: 2s - loss: 0.0359 - acc: 0.988 - ETA: 1s - loss: 0.0361 - acc: 0.988 - ETA: 1s - loss: 0.0361 - acc: 0.988 - ETA: 1s - loss: 0.0359 - acc: 0.988 - ETA: 1s - loss: 0.0359 - acc: 0.988 - ETA: 1s - loss: 0.0359 - acc: 0.988 - ETA: 1s - loss: 0.0361 - acc: 0.988 - ETA: 1s - loss: 0.0359 - acc: 0.988 - ETA: 1s - loss: 0.0361 - acc: 0.988 - ETA: 1s - loss: 0.0359 - acc: 0.988 - ETA: 1s - loss: 0.0358 - acc: 0.988 - ETA: 1s - loss: 0.0356 - acc: 0.988 - ETA: 1s - loss: 0.0355 - acc: 0.988 - ETA: 1s - loss: 0.0356 - acc: 0.988 - ETA: 1s - loss: 0.0356 - acc: 0.988 - ETA: 1s - loss: 0.0358 - acc: 0.988 - ETA: 1s - loss: 0.0361 - acc: 0.988 - ETA: 1s - loss: 0.0360 - acc: 0.988 - ETA: 0s - loss: 0.0360 - acc: 0.988 - ETA: 0s - loss: 0.0360 - acc: 0.988 - ETA: 0s - loss: 0.0361 - acc: 0.988 - ETA: 0s - loss: 0.0363 - acc: 0.988 - ETA: 0s - loss: 0.0362 - acc: 0.988 - ETA: 0s - loss: 0.0361 - acc: 0.988 - ETA: 0s - loss: 0.0362 - acc: 0.988 - ETA: 0s - loss: 0.0362 - acc: 0.988 - ETA: 0s - loss: 0.0362 - acc: 0.988 - ETA: 0s - loss: 0.0361 - acc: 0.988 - ETA: 0s - loss: 0.0362 - acc: 0.988 - ETA: 0s - loss: 0.0360 - acc: 0.988 - ETA: 0s - loss: 0.0361 - acc: 0.988 - ETA: 0s - loss: 0.0361 - acc: 0.988 - ETA: 0s - loss: 0.0362 - acc: 0.988 - ETA: 0s - loss: 0.0363 - acc: 0.988 - ETA: 0s - loss: 0.0362 - acc: 0.988 - ETA: 0s - loss: 0.0363 - acc: 0.988 - ETA: 0s - loss: 0.0362 - acc: 0.988 - 7s 139us/sample - loss: 0.0362 - acc: 0.9882 - val_loss: 0.2333 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0014896690244560313.\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49740/49740 [==============================] - ETA: 6s - loss: 0.0257 - acc: 1.000 - ETA: 6s - loss: 0.0279 - acc: 0.987 - ETA: 6s - loss: 0.0241 - acc: 0.990 - ETA: 6s - loss: 0.0265 - acc: 0.990 - ETA: 6s - loss: 0.0300 - acc: 0.990 - ETA: 6s - loss: 0.0290 - acc: 0.990 - ETA: 6s - loss: 0.0264 - acc: 0.991 - ETA: 6s - loss: 0.0267 - acc: 0.991 - ETA: 6s - loss: 0.0258 - acc: 0.991 - ETA: 6s - loss: 0.0276 - acc: 0.991 - ETA: 5s - loss: 0.0280 - acc: 0.991 - ETA: 5s - loss: 0.0280 - acc: 0.991 - ETA: 5s - loss: 0.0286 - acc: 0.991 - ETA: 5s - loss: 0.0303 - acc: 0.990 - ETA: 5s - loss: 0.0310 - acc: 0.989 - ETA: 5s - loss: 0.0295 - acc: 0.990 - ETA: 5s - loss: 0.0297 - acc: 0.990 - ETA: 5s - loss: 0.0302 - acc: 0.990 - ETA: 5s - loss: 0.0297 - acc: 0.990 - ETA: 5s - loss: 0.0297 - acc: 0.990 - ETA: 5s - loss: 0.0304 - acc: 0.990 - ETA: 5s - loss: 0.0309 - acc: 0.990 - ETA: 5s - loss: 0.0306 - acc: 0.990 - ETA: 5s - loss: 0.0300 - acc: 0.990 - ETA: 5s - loss: 0.0308 - acc: 0.990 - ETA: 5s - loss: 0.0304 - acc: 0.990 - ETA: 5s - loss: 0.0311 - acc: 0.990 - ETA: 5s - loss: 0.0312 - acc: 0.989 - ETA: 4s - loss: 0.0309 - acc: 0.990 - ETA: 4s - loss: 0.0310 - acc: 0.990 - ETA: 4s - loss: 0.0309 - acc: 0.990 - ETA: 4s - loss: 0.0304 - acc: 0.990 - ETA: 4s - loss: 0.0313 - acc: 0.989 - ETA: 4s - loss: 0.0318 - acc: 0.989 - ETA: 4s - loss: 0.0320 - acc: 0.989 - ETA: 4s - loss: 0.0319 - acc: 0.989 - ETA: 4s - loss: 0.0320 - acc: 0.989 - ETA: 4s - loss: 0.0322 - acc: 0.989 - ETA: 4s - loss: 0.0322 - acc: 0.989 - ETA: 4s - loss: 0.0321 - acc: 0.989 - ETA: 4s - loss: 0.0318 - acc: 0.989 - ETA: 4s - loss: 0.0318 - acc: 0.989 - ETA: 4s - loss: 0.0318 - acc: 0.989 - ETA: 4s - loss: 0.0313 - acc: 0.990 - ETA: 4s - loss: 0.0316 - acc: 0.990 - ETA: 3s - loss: 0.0315 - acc: 0.990 - ETA: 3s - loss: 0.0317 - acc: 0.990 - ETA: 3s - loss: 0.0319 - acc: 0.990 - ETA: 3s - loss: 0.0319 - acc: 0.990 - ETA: 3s - loss: 0.0317 - acc: 0.990 - ETA: 3s - loss: 0.0317 - acc: 0.990 - ETA: 3s - loss: 0.0320 - acc: 0.990 - ETA: 3s - loss: 0.0323 - acc: 0.990 - ETA: 3s - loss: 0.0326 - acc: 0.990 - ETA: 3s - loss: 0.0326 - acc: 0.990 - ETA: 3s - loss: 0.0326 - acc: 0.990 - ETA: 3s - loss: 0.0321 - acc: 0.990 - ETA: 3s - loss: 0.0320 - acc: 0.990 - ETA: 3s - loss: 0.0322 - acc: 0.990 - ETA: 3s - loss: 0.0318 - acc: 0.990 - ETA: 3s - loss: 0.0317 - acc: 0.990 - ETA: 3s - loss: 0.0316 - acc: 0.990 - ETA: 2s - loss: 0.0314 - acc: 0.990 - ETA: 2s - loss: 0.0314 - acc: 0.990 - ETA: 2s - loss: 0.0311 - acc: 0.990 - ETA: 2s - loss: 0.0308 - acc: 0.990 - ETA: 2s - loss: 0.0308 - acc: 0.990 - ETA: 2s - loss: 0.0307 - acc: 0.990 - ETA: 2s - loss: 0.0307 - acc: 0.990 - ETA: 2s - loss: 0.0310 - acc: 0.990 - ETA: 2s - loss: 0.0311 - acc: 0.990 - ETA: 2s - loss: 0.0310 - acc: 0.990 - ETA: 2s - loss: 0.0311 - acc: 0.990 - ETA: 2s - loss: 0.0310 - acc: 0.990 - ETA: 2s - loss: 0.0309 - acc: 0.990 - ETA: 2s - loss: 0.0308 - acc: 0.990 - ETA: 2s - loss: 0.0306 - acc: 0.990 - ETA: 2s - loss: 0.0304 - acc: 0.990 - ETA: 2s - loss: 0.0307 - acc: 0.990 - ETA: 2s - loss: 0.0312 - acc: 0.990 - ETA: 1s - loss: 0.0313 - acc: 0.990 - ETA: 1s - loss: 0.0318 - acc: 0.990 - ETA: 1s - loss: 0.0316 - acc: 0.990 - ETA: 1s - loss: 0.0316 - acc: 0.990 - ETA: 1s - loss: 0.0315 - acc: 0.990 - ETA: 1s - loss: 0.0314 - acc: 0.990 - ETA: 1s - loss: 0.0313 - acc: 0.990 - ETA: 1s - loss: 0.0314 - acc: 0.990 - ETA: 1s - loss: 0.0314 - acc: 0.990 - ETA: 1s - loss: 0.0313 - acc: 0.990 - ETA: 1s - loss: 0.0312 - acc: 0.990 - ETA: 1s - loss: 0.0316 - acc: 0.990 - ETA: 1s - loss: 0.0315 - acc: 0.990 - ETA: 1s - loss: 0.0315 - acc: 0.990 - ETA: 1s - loss: 0.0314 - acc: 0.990 - ETA: 1s - loss: 0.0314 - acc: 0.990 - ETA: 1s - loss: 0.0315 - acc: 0.990 - ETA: 0s - loss: 0.0314 - acc: 0.990 - ETA: 0s - loss: 0.0313 - acc: 0.990 - ETA: 0s - loss: 0.0313 - acc: 0.990 - ETA: 0s - loss: 0.0312 - acc: 0.990 - ETA: 0s - loss: 0.0311 - acc: 0.990 - ETA: 0s - loss: 0.0312 - acc: 0.990 - ETA: 0s - loss: 0.0314 - acc: 0.990 - ETA: 0s - loss: 0.0314 - acc: 0.990 - ETA: 0s - loss: 0.0313 - acc: 0.990 - ETA: 0s - loss: 0.0312 - acc: 0.990 - ETA: 0s - loss: 0.0311 - acc: 0.990 - ETA: 0s - loss: 0.0310 - acc: 0.990 - ETA: 0s - loss: 0.0310 - acc: 0.990 - ETA: 0s - loss: 0.0309 - acc: 0.990 - ETA: 0s - loss: 0.0310 - acc: 0.990 - ETA: 0s - loss: 0.0309 - acc: 0.990 - ETA: 0s - loss: 0.0310 - acc: 0.990 - ETA: 0s - loss: 0.0310 - acc: 0.990 - ETA: 0s - loss: 0.0310 - acc: 0.990 - 7s 135us/sample - loss: 0.0311 - acc: 0.9908 - val_loss: 3.5416 - val_acc: 0.3850\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001095741367357279.\n",
      "Epoch 10/20\n",
      "49740/49740 [==============================] - ETA: 7s - loss: 0.0196 - acc: 0.984 - ETA: 6s - loss: 0.0280 - acc: 0.984 - ETA: 6s - loss: 0.0275 - acc: 0.986 - ETA: 6s - loss: 0.0274 - acc: 0.987 - ETA: 6s - loss: 0.0260 - acc: 0.989 - ETA: 6s - loss: 0.0264 - acc: 0.989 - ETA: 6s - loss: 0.0288 - acc: 0.989 - ETA: 5s - loss: 0.0324 - acc: 0.990 - ETA: 5s - loss: 0.0308 - acc: 0.990 - ETA: 5s - loss: 0.0295 - acc: 0.991 - ETA: 5s - loss: 0.0285 - acc: 0.992 - ETA: 5s - loss: 0.0281 - acc: 0.992 - ETA: 5s - loss: 0.0277 - acc: 0.991 - ETA: 5s - loss: 0.0277 - acc: 0.991 - ETA: 5s - loss: 0.0273 - acc: 0.992 - ETA: 5s - loss: 0.0277 - acc: 0.992 - ETA: 5s - loss: 0.0293 - acc: 0.992 - ETA: 5s - loss: 0.0293 - acc: 0.992 - ETA: 5s - loss: 0.0288 - acc: 0.992 - ETA: 5s - loss: 0.0283 - acc: 0.992 - ETA: 5s - loss: 0.0282 - acc: 0.993 - ETA: 5s - loss: 0.0289 - acc: 0.992 - ETA: 5s - loss: 0.0292 - acc: 0.992 - ETA: 5s - loss: 0.0290 - acc: 0.992 - ETA: 5s - loss: 0.0289 - acc: 0.992 - ETA: 4s - loss: 0.0288 - acc: 0.992 - ETA: 4s - loss: 0.0287 - acc: 0.992 - ETA: 4s - loss: 0.0292 - acc: 0.992 - ETA: 4s - loss: 0.0292 - acc: 0.992 - ETA: 4s - loss: 0.0291 - acc: 0.992 - ETA: 4s - loss: 0.0290 - acc: 0.992 - ETA: 4s - loss: 0.0291 - acc: 0.992 - ETA: 4s - loss: 0.0295 - acc: 0.992 - ETA: 4s - loss: 0.0293 - acc: 0.992 - ETA: 4s - loss: 0.0292 - acc: 0.992 - ETA: 4s - loss: 0.0288 - acc: 0.992 - ETA: 4s - loss: 0.0291 - acc: 0.992 - ETA: 4s - loss: 0.0287 - acc: 0.992 - ETA: 4s - loss: 0.0286 - acc: 0.992 - ETA: 4s - loss: 0.0286 - acc: 0.992 - ETA: 4s - loss: 0.0285 - acc: 0.992 - ETA: 4s - loss: 0.0284 - acc: 0.992 - ETA: 4s - loss: 0.0288 - acc: 0.992 - ETA: 4s - loss: 0.0287 - acc: 0.992 - ETA: 3s - loss: 0.0286 - acc: 0.992 - ETA: 3s - loss: 0.0287 - acc: 0.992 - ETA: 3s - loss: 0.0286 - acc: 0.992 - ETA: 3s - loss: 0.0284 - acc: 0.992 - ETA: 3s - loss: 0.0282 - acc: 0.992 - ETA: 3s - loss: 0.0280 - acc: 0.992 - ETA: 3s - loss: 0.0280 - acc: 0.992 - ETA: 3s - loss: 0.0279 - acc: 0.992 - ETA: 3s - loss: 0.0278 - acc: 0.992 - ETA: 3s - loss: 0.0279 - acc: 0.992 - ETA: 3s - loss: 0.0280 - acc: 0.992 - ETA: 3s - loss: 0.0280 - acc: 0.992 - ETA: 3s - loss: 0.0278 - acc: 0.992 - ETA: 3s - loss: 0.0276 - acc: 0.992 - ETA: 3s - loss: 0.0279 - acc: 0.992 - ETA: 3s - loss: 0.0278 - acc: 0.992 - ETA: 3s - loss: 0.0280 - acc: 0.992 - ETA: 3s - loss: 0.0283 - acc: 0.992 - ETA: 3s - loss: 0.0282 - acc: 0.992 - ETA: 3s - loss: 0.0282 - acc: 0.992 - ETA: 2s - loss: 0.0280 - acc: 0.992 - ETA: 2s - loss: 0.0279 - acc: 0.992 - ETA: 2s - loss: 0.0278 - acc: 0.992 - ETA: 2s - loss: 0.0279 - acc: 0.992 - ETA: 2s - loss: 0.0279 - acc: 0.992 - ETA: 2s - loss: 0.0280 - acc: 0.992 - ETA: 2s - loss: 0.0279 - acc: 0.992 - ETA: 2s - loss: 0.0279 - acc: 0.992 - ETA: 2s - loss: 0.0278 - acc: 0.992 - ETA: 2s - loss: 0.0277 - acc: 0.992 - ETA: 2s - loss: 0.0276 - acc: 0.992 - ETA: 2s - loss: 0.0277 - acc: 0.992 - ETA: 2s - loss: 0.0277 - acc: 0.992 - ETA: 2s - loss: 0.0275 - acc: 0.992 - ETA: 2s - loss: 0.0274 - acc: 0.992 - ETA: 2s - loss: 0.0272 - acc: 0.992 - ETA: 2s - loss: 0.0270 - acc: 0.992 - ETA: 2s - loss: 0.0271 - acc: 0.992 - ETA: 2s - loss: 0.0272 - acc: 0.992 - ETA: 1s - loss: 0.0272 - acc: 0.992 - ETA: 1s - loss: 0.0271 - acc: 0.992 - ETA: 1s - loss: 0.0270 - acc: 0.992 - ETA: 1s - loss: 0.0269 - acc: 0.992 - ETA: 1s - loss: 0.0269 - acc: 0.992 - ETA: 1s - loss: 0.0270 - acc: 0.992 - ETA: 1s - loss: 0.0273 - acc: 0.992 - ETA: 1s - loss: 0.0273 - acc: 0.992 - ETA: 1s - loss: 0.0273 - acc: 0.992 - ETA: 1s - loss: 0.0273 - acc: 0.992 - ETA: 1s - loss: 0.0271 - acc: 0.992 - ETA: 1s - loss: 0.0270 - acc: 0.992 - ETA: 1s - loss: 0.0271 - acc: 0.992 - ETA: 1s - loss: 0.0272 - acc: 0.992 - ETA: 1s - loss: 0.0272 - acc: 0.992 - ETA: 1s - loss: 0.0274 - acc: 0.992 - ETA: 1s - loss: 0.0275 - acc: 0.992 - ETA: 1s - loss: 0.0274 - acc: 0.992 - ETA: 1s - loss: 0.0273 - acc: 0.992 - ETA: 1s - loss: 0.0274 - acc: 0.992 - ETA: 0s - loss: 0.0273 - acc: 0.992 - ETA: 0s - loss: 0.0273 - acc: 0.992 - ETA: 0s - loss: 0.0275 - acc: 0.992 - ETA: 0s - loss: 0.0274 - acc: 0.992 - ETA: 0s - loss: 0.0274 - acc: 0.992 - ETA: 0s - loss: 0.0274 - acc: 0.991 - ETA: 0s - loss: 0.0274 - acc: 0.991 - ETA: 0s - loss: 0.0275 - acc: 0.991 - ETA: 0s - loss: 0.0274 - acc: 0.991 - ETA: 0s - loss: 0.0272 - acc: 0.992 - ETA: 0s - loss: 0.0273 - acc: 0.991 - ETA: 0s - loss: 0.0273 - acc: 0.991 - ETA: 0s - loss: 0.0272 - acc: 0.992 - ETA: 0s - loss: 0.0273 - acc: 0.991 - ETA: 0s - loss: 0.0274 - acc: 0.991 - ETA: 0s - loss: 0.0273 - acc: 0.991 - ETA: 0s - loss: 0.0274 - acc: 0.991 - ETA: 0s - loss: 0.0274 - acc: 0.991 - 7s 138us/sample - loss: 0.0274 - acc: 0.9917 - val_loss: 1.5736 - val_acc: 0.7349\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.000813479866945048.\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49740/49740 [==============================] - ETA: 6s - loss: 0.0075 - acc: 1.000 - ETA: 6s - loss: 0.0274 - acc: 0.990 - ETA: 6s - loss: 0.0230 - acc: 0.992 - ETA: 6s - loss: 0.0268 - acc: 0.989 - ETA: 6s - loss: 0.0315 - acc: 0.989 - ETA: 6s - loss: 0.0298 - acc: 0.990 - ETA: 6s - loss: 0.0271 - acc: 0.991 - ETA: 6s - loss: 0.0312 - acc: 0.991 - ETA: 6s - loss: 0.0300 - acc: 0.991 - ETA: 6s - loss: 0.0313 - acc: 0.991 - ETA: 6s - loss: 0.0305 - acc: 0.991 - ETA: 6s - loss: 0.0320 - acc: 0.991 - ETA: 6s - loss: 0.0304 - acc: 0.991 - ETA: 6s - loss: 0.0310 - acc: 0.991 - ETA: 6s - loss: 0.0304 - acc: 0.991 - ETA: 5s - loss: 0.0309 - acc: 0.991 - ETA: 5s - loss: 0.0297 - acc: 0.992 - ETA: 5s - loss: 0.0294 - acc: 0.992 - ETA: 5s - loss: 0.0287 - acc: 0.992 - ETA: 5s - loss: 0.0284 - acc: 0.992 - ETA: 5s - loss: 0.0282 - acc: 0.992 - ETA: 5s - loss: 0.0297 - acc: 0.991 - ETA: 5s - loss: 0.0295 - acc: 0.991 - ETA: 5s - loss: 0.0291 - acc: 0.991 - ETA: 5s - loss: 0.0286 - acc: 0.991 - ETA: 5s - loss: 0.0299 - acc: 0.991 - ETA: 5s - loss: 0.0291 - acc: 0.991 - ETA: 5s - loss: 0.0287 - acc: 0.991 - ETA: 5s - loss: 0.0281 - acc: 0.992 - ETA: 5s - loss: 0.0283 - acc: 0.992 - ETA: 5s - loss: 0.0281 - acc: 0.992 - ETA: 4s - loss: 0.0288 - acc: 0.992 - ETA: 4s - loss: 0.0289 - acc: 0.991 - ETA: 4s - loss: 0.0293 - acc: 0.991 - ETA: 4s - loss: 0.0290 - acc: 0.991 - ETA: 4s - loss: 0.0292 - acc: 0.991 - ETA: 4s - loss: 0.0289 - acc: 0.991 - ETA: 4s - loss: 0.0286 - acc: 0.991 - ETA: 4s - loss: 0.0288 - acc: 0.991 - ETA: 4s - loss: 0.0291 - acc: 0.991 - ETA: 4s - loss: 0.0292 - acc: 0.991 - ETA: 4s - loss: 0.0292 - acc: 0.991 - ETA: 4s - loss: 0.0289 - acc: 0.991 - ETA: 4s - loss: 0.0289 - acc: 0.991 - ETA: 4s - loss: 0.0287 - acc: 0.991 - ETA: 4s - loss: 0.0284 - acc: 0.991 - ETA: 4s - loss: 0.0282 - acc: 0.991 - ETA: 4s - loss: 0.0285 - acc: 0.991 - ETA: 4s - loss: 0.0288 - acc: 0.991 - ETA: 3s - loss: 0.0287 - acc: 0.991 - ETA: 3s - loss: 0.0286 - acc: 0.991 - ETA: 3s - loss: 0.0286 - acc: 0.991 - ETA: 3s - loss: 0.0288 - acc: 0.991 - ETA: 3s - loss: 0.0285 - acc: 0.991 - ETA: 3s - loss: 0.0283 - acc: 0.991 - ETA: 3s - loss: 0.0280 - acc: 0.991 - ETA: 3s - loss: 0.0282 - acc: 0.991 - ETA: 3s - loss: 0.0280 - acc: 0.991 - ETA: 3s - loss: 0.0280 - acc: 0.991 - ETA: 3s - loss: 0.0278 - acc: 0.991 - ETA: 3s - loss: 0.0277 - acc: 0.991 - ETA: 3s - loss: 0.0278 - acc: 0.991 - ETA: 3s - loss: 0.0280 - acc: 0.991 - ETA: 3s - loss: 0.0277 - acc: 0.991 - ETA: 3s - loss: 0.0277 - acc: 0.991 - ETA: 3s - loss: 0.0282 - acc: 0.991 - ETA: 3s - loss: 0.0280 - acc: 0.991 - ETA: 2s - loss: 0.0279 - acc: 0.991 - ETA: 2s - loss: 0.0279 - acc: 0.991 - ETA: 2s - loss: 0.0279 - acc: 0.991 - ETA: 2s - loss: 0.0279 - acc: 0.991 - ETA: 2s - loss: 0.0277 - acc: 0.991 - ETA: 2s - loss: 0.0278 - acc: 0.991 - ETA: 2s - loss: 0.0277 - acc: 0.991 - ETA: 2s - loss: 0.0275 - acc: 0.991 - ETA: 2s - loss: 0.0274 - acc: 0.991 - ETA: 2s - loss: 0.0273 - acc: 0.991 - ETA: 2s - loss: 0.0272 - acc: 0.991 - ETA: 2s - loss: 0.0271 - acc: 0.991 - ETA: 2s - loss: 0.0273 - acc: 0.991 - ETA: 2s - loss: 0.0271 - acc: 0.991 - ETA: 2s - loss: 0.0270 - acc: 0.991 - ETA: 2s - loss: 0.0270 - acc: 0.991 - ETA: 2s - loss: 0.0273 - acc: 0.991 - ETA: 2s - loss: 0.0273 - acc: 0.991 - ETA: 2s - loss: 0.0272 - acc: 0.991 - ETA: 2s - loss: 0.0272 - acc: 0.991 - ETA: 1s - loss: 0.0273 - acc: 0.991 - ETA: 1s - loss: 0.0273 - acc: 0.991 - ETA: 1s - loss: 0.0273 - acc: 0.991 - ETA: 1s - loss: 0.0273 - acc: 0.991 - ETA: 1s - loss: 0.0272 - acc: 0.991 - ETA: 1s - loss: 0.0272 - acc: 0.991 - ETA: 1s - loss: 0.0271 - acc: 0.991 - ETA: 1s - loss: 0.0270 - acc: 0.991 - ETA: 1s - loss: 0.0269 - acc: 0.991 - ETA: 1s - loss: 0.0268 - acc: 0.991 - ETA: 1s - loss: 0.0268 - acc: 0.991 - ETA: 1s - loss: 0.0268 - acc: 0.991 - ETA: 1s - loss: 0.0266 - acc: 0.991 - ETA: 1s - loss: 0.0265 - acc: 0.991 - ETA: 1s - loss: 0.0265 - acc: 0.991 - ETA: 1s - loss: 0.0264 - acc: 0.991 - ETA: 1s - loss: 0.0264 - acc: 0.991 - ETA: 1s - loss: 0.0264 - acc: 0.991 - ETA: 1s - loss: 0.0262 - acc: 0.992 - ETA: 0s - loss: 0.0261 - acc: 0.992 - ETA: 0s - loss: 0.0258 - acc: 0.992 - ETA: 0s - loss: 0.0257 - acc: 0.992 - ETA: 0s - loss: 0.0258 - acc: 0.992 - ETA: 0s - loss: 0.0257 - acc: 0.992 - ETA: 0s - loss: 0.0257 - acc: 0.992 - ETA: 0s - loss: 0.0257 - acc: 0.992 - ETA: 0s - loss: 0.0257 - acc: 0.992 - ETA: 0s - loss: 0.0256 - acc: 0.992 - ETA: 0s - loss: 0.0256 - acc: 0.992 - ETA: 0s - loss: 0.0255 - acc: 0.992 - ETA: 0s - loss: 0.0254 - acc: 0.992 - ETA: 0s - loss: 0.0256 - acc: 0.992 - ETA: 0s - loss: 0.0256 - acc: 0.992 - ETA: 0s - loss: 0.0257 - acc: 0.992 - ETA: 0s - loss: 0.0258 - acc: 0.992 - ETA: 0s - loss: 0.0257 - acc: 0.992 - ETA: 0s - loss: 0.0255 - acc: 0.992 - 7s 139us/sample - loss: 0.0256 - acc: 0.9922 - val_loss: 0.0493 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0006112306641301482.\n",
      "Epoch 12/20\n",
      "49740/49740 [==============================] - ETA: 6s - loss: 0.0229 - acc: 0.984 - ETA: 6s - loss: 0.0136 - acc: 0.996 - ETA: 7s - loss: 0.0117 - acc: 0.997 - ETA: 6s - loss: 0.0209 - acc: 0.996 - ETA: 6s - loss: 0.0196 - acc: 0.997 - ETA: 6s - loss: 0.0194 - acc: 0.996 - ETA: 6s - loss: 0.0197 - acc: 0.995 - ETA: 6s - loss: 0.0192 - acc: 0.995 - ETA: 6s - loss: 0.0201 - acc: 0.995 - ETA: 6s - loss: 0.0227 - acc: 0.994 - ETA: 6s - loss: 0.0217 - acc: 0.995 - ETA: 6s - loss: 0.0223 - acc: 0.994 - ETA: 6s - loss: 0.0219 - acc: 0.994 - ETA: 6s - loss: 0.0225 - acc: 0.993 - ETA: 6s - loss: 0.0221 - acc: 0.993 - ETA: 6s - loss: 0.0216 - acc: 0.993 - ETA: 6s - loss: 0.0211 - acc: 0.993 - ETA: 5s - loss: 0.0212 - acc: 0.993 - ETA: 5s - loss: 0.0212 - acc: 0.993 - ETA: 5s - loss: 0.0217 - acc: 0.993 - ETA: 5s - loss: 0.0215 - acc: 0.993 - ETA: 5s - loss: 0.0218 - acc: 0.993 - ETA: 5s - loss: 0.0214 - acc: 0.993 - ETA: 5s - loss: 0.0213 - acc: 0.993 - ETA: 5s - loss: 0.0214 - acc: 0.993 - ETA: 5s - loss: 0.0213 - acc: 0.993 - ETA: 5s - loss: 0.0217 - acc: 0.993 - ETA: 5s - loss: 0.0217 - acc: 0.993 - ETA: 5s - loss: 0.0217 - acc: 0.993 - ETA: 5s - loss: 0.0216 - acc: 0.993 - ETA: 5s - loss: 0.0215 - acc: 0.993 - ETA: 5s - loss: 0.0216 - acc: 0.993 - ETA: 5s - loss: 0.0212 - acc: 0.993 - ETA: 5s - loss: 0.0211 - acc: 0.994 - ETA: 5s - loss: 0.0210 - acc: 0.993 - ETA: 5s - loss: 0.0210 - acc: 0.993 - ETA: 5s - loss: 0.0211 - acc: 0.993 - ETA: 5s - loss: 0.0211 - acc: 0.993 - ETA: 5s - loss: 0.0212 - acc: 0.993 - ETA: 5s - loss: 0.0213 - acc: 0.993 - ETA: 5s - loss: 0.0212 - acc: 0.993 - ETA: 5s - loss: 0.0214 - acc: 0.993 - ETA: 5s - loss: 0.0211 - acc: 0.993 - ETA: 5s - loss: 0.0211 - acc: 0.993 - ETA: 5s - loss: 0.0219 - acc: 0.993 - ETA: 4s - loss: 0.0216 - acc: 0.993 - ETA: 4s - loss: 0.0216 - acc: 0.993 - ETA: 4s - loss: 0.0216 - acc: 0.993 - ETA: 4s - loss: 0.0213 - acc: 0.993 - ETA: 4s - loss: 0.0213 - acc: 0.993 - ETA: 4s - loss: 0.0212 - acc: 0.993 - ETA: 4s - loss: 0.0212 - acc: 0.993 - ETA: 4s - loss: 0.0211 - acc: 0.993 - ETA: 4s - loss: 0.0214 - acc: 0.993 - ETA: 4s - loss: 0.0217 - acc: 0.993 - ETA: 4s - loss: 0.0219 - acc: 0.993 - ETA: 4s - loss: 0.0219 - acc: 0.993 - ETA: 4s - loss: 0.0219 - acc: 0.993 - ETA: 4s - loss: 0.0218 - acc: 0.993 - ETA: 4s - loss: 0.0218 - acc: 0.993 - ETA: 4s - loss: 0.0219 - acc: 0.993 - ETA: 4s - loss: 0.0218 - acc: 0.993 - ETA: 4s - loss: 0.0218 - acc: 0.993 - ETA: 4s - loss: 0.0217 - acc: 0.993 - ETA: 4s - loss: 0.0218 - acc: 0.993 - ETA: 4s - loss: 0.0220 - acc: 0.993 - ETA: 4s - loss: 0.0223 - acc: 0.993 - ETA: 3s - loss: 0.0226 - acc: 0.993 - ETA: 3s - loss: 0.0225 - acc: 0.993 - ETA: 3s - loss: 0.0225 - acc: 0.993 - ETA: 3s - loss: 0.0226 - acc: 0.992 - ETA: 3s - loss: 0.0227 - acc: 0.992 - ETA: 3s - loss: 0.0230 - acc: 0.992 - ETA: 3s - loss: 0.0229 - acc: 0.992 - ETA: 3s - loss: 0.0229 - acc: 0.992 - ETA: 3s - loss: 0.0228 - acc: 0.992 - ETA: 3s - loss: 0.0234 - acc: 0.992 - ETA: 3s - loss: 0.0234 - acc: 0.992 - ETA: 3s - loss: 0.0236 - acc: 0.992 - ETA: 3s - loss: 0.0235 - acc: 0.992 - ETA: 3s - loss: 0.0236 - acc: 0.992 - ETA: 3s - loss: 0.0236 - acc: 0.992 - ETA: 2s - loss: 0.0235 - acc: 0.992 - ETA: 2s - loss: 0.0235 - acc: 0.992 - ETA: 2s - loss: 0.0236 - acc: 0.992 - ETA: 2s - loss: 0.0234 - acc: 0.992 - ETA: 2s - loss: 0.0234 - acc: 0.992 - ETA: 2s - loss: 0.0235 - acc: 0.992 - ETA: 2s - loss: 0.0235 - acc: 0.992 - ETA: 2s - loss: 0.0236 - acc: 0.992 - ETA: 2s - loss: 0.0236 - acc: 0.992 - ETA: 2s - loss: 0.0236 - acc: 0.992 - ETA: 2s - loss: 0.0236 - acc: 0.992 - ETA: 2s - loss: 0.0235 - acc: 0.992 - ETA: 2s - loss: 0.0235 - acc: 0.992 - ETA: 2s - loss: 0.0234 - acc: 0.992 - ETA: 2s - loss: 0.0233 - acc: 0.992 - ETA: 2s - loss: 0.0232 - acc: 0.992 - ETA: 2s - loss: 0.0233 - acc: 0.992 - ETA: 1s - loss: 0.0234 - acc: 0.992 - ETA: 1s - loss: 0.0233 - acc: 0.992 - ETA: 1s - loss: 0.0235 - acc: 0.992 - ETA: 1s - loss: 0.0236 - acc: 0.992 - ETA: 1s - loss: 0.0236 - acc: 0.992 - ETA: 1s - loss: 0.0236 - acc: 0.992 - ETA: 1s - loss: 0.0237 - acc: 0.992 - ETA: 1s - loss: 0.0237 - acc: 0.992 - ETA: 1s - loss: 0.0238 - acc: 0.992 - ETA: 1s - loss: 0.0237 - acc: 0.992 - ETA: 1s - loss: 0.0238 - acc: 0.992 - ETA: 1s - loss: 0.0237 - acc: 0.992 - ETA: 1s - loss: 0.0237 - acc: 0.992 - ETA: 1s - loss: 0.0239 - acc: 0.992 - ETA: 1s - loss: 0.0239 - acc: 0.992 - ETA: 1s - loss: 0.0240 - acc: 0.992 - ETA: 1s - loss: 0.0240 - acc: 0.992 - ETA: 1s - loss: 0.0243 - acc: 0.992 - ETA: 1s - loss: 0.0242 - acc: 0.992 - ETA: 0s - loss: 0.0242 - acc: 0.992 - ETA: 0s - loss: 0.0241 - acc: 0.992 - ETA: 0s - loss: 0.0240 - acc: 0.992 - ETA: 0s - loss: 0.0239 - acc: 0.992 - ETA: 0s - loss: 0.0240 - acc: 0.992 - ETA: 0s - loss: 0.0244 - acc: 0.992 - ETA: 0s - loss: 0.0244 - acc: 0.992 - ETA: 0s - loss: 0.0243 - acc: 0.992 - ETA: 0s - loss: 0.0242 - acc: 0.992 - ETA: 0s - loss: 0.0241 - acc: 0.992 - ETA: 0s - loss: 0.0241 - acc: 0.992 - ETA: 0s - loss: 0.0240 - acc: 0.992 - ETA: 0s - loss: 0.0239 - acc: 0.992 - ETA: 0s - loss: 0.0238 - acc: 0.992 - ETA: 0s - loss: 0.0239 - acc: 0.992 - ETA: 0s - loss: 0.0239 - acc: 0.992 - ETA: 0s - loss: 0.0240 - acc: 0.992 - 8s 166us/sample - loss: 0.0240 - acc: 0.9925 - val_loss: 0.0844 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.00046631277777468366.\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49740/49740 [==============================] - ETA: 8s - loss: 0.0205 - acc: 0.992 - ETA: 7s - loss: 0.0205 - acc: 0.994 - ETA: 7s - loss: 0.0211 - acc: 0.993 - ETA: 7s - loss: 0.0250 - acc: 0.991 - ETA: 7s - loss: 0.0269 - acc: 0.990 - ETA: 7s - loss: 0.0247 - acc: 0.991 - ETA: 7s - loss: 0.0226 - acc: 0.991 - ETA: 7s - loss: 0.0220 - acc: 0.991 - ETA: 7s - loss: 0.0203 - acc: 0.991 - ETA: 7s - loss: 0.0201 - acc: 0.991 - ETA: 7s - loss: 0.0200 - acc: 0.992 - ETA: 7s - loss: 0.0229 - acc: 0.992 - ETA: 7s - loss: 0.0228 - acc: 0.992 - ETA: 7s - loss: 0.0220 - acc: 0.993 - ETA: 6s - loss: 0.0210 - acc: 0.993 - ETA: 6s - loss: 0.0209 - acc: 0.993 - ETA: 6s - loss: 0.0208 - acc: 0.993 - ETA: 6s - loss: 0.0212 - acc: 0.993 - ETA: 6s - loss: 0.0213 - acc: 0.993 - ETA: 6s - loss: 0.0230 - acc: 0.992 - ETA: 6s - loss: 0.0234 - acc: 0.992 - ETA: 6s - loss: 0.0228 - acc: 0.992 - ETA: 6s - loss: 0.0223 - acc: 0.992 - ETA: 5s - loss: 0.0222 - acc: 0.993 - ETA: 5s - loss: 0.0220 - acc: 0.993 - ETA: 5s - loss: 0.0220 - acc: 0.993 - ETA: 5s - loss: 0.0220 - acc: 0.993 - ETA: 5s - loss: 0.0219 - acc: 0.992 - ETA: 5s - loss: 0.0217 - acc: 0.993 - ETA: 5s - loss: 0.0223 - acc: 0.993 - ETA: 5s - loss: 0.0221 - acc: 0.993 - ETA: 5s - loss: 0.0219 - acc: 0.993 - ETA: 5s - loss: 0.0219 - acc: 0.993 - ETA: 5s - loss: 0.0221 - acc: 0.993 - ETA: 5s - loss: 0.0226 - acc: 0.992 - ETA: 5s - loss: 0.0236 - acc: 0.992 - ETA: 5s - loss: 0.0238 - acc: 0.992 - ETA: 5s - loss: 0.0236 - acc: 0.992 - ETA: 5s - loss: 0.0237 - acc: 0.992 - ETA: 5s - loss: 0.0233 - acc: 0.992 - ETA: 5s - loss: 0.0233 - acc: 0.992 - ETA: 5s - loss: 0.0245 - acc: 0.992 - ETA: 4s - loss: 0.0247 - acc: 0.992 - ETA: 4s - loss: 0.0246 - acc: 0.992 - ETA: 4s - loss: 0.0243 - acc: 0.992 - ETA: 4s - loss: 0.0245 - acc: 0.992 - ETA: 4s - loss: 0.0246 - acc: 0.992 - ETA: 4s - loss: 0.0249 - acc: 0.992 - ETA: 4s - loss: 0.0250 - acc: 0.992 - ETA: 4s - loss: 0.0248 - acc: 0.992 - ETA: 4s - loss: 0.0246 - acc: 0.992 - ETA: 4s - loss: 0.0244 - acc: 0.992 - ETA: 4s - loss: 0.0244 - acc: 0.992 - ETA: 4s - loss: 0.0240 - acc: 0.992 - ETA: 4s - loss: 0.0238 - acc: 0.992 - ETA: 4s - loss: 0.0238 - acc: 0.992 - ETA: 4s - loss: 0.0237 - acc: 0.992 - ETA: 4s - loss: 0.0239 - acc: 0.992 - ETA: 4s - loss: 0.0238 - acc: 0.992 - ETA: 4s - loss: 0.0238 - acc: 0.992 - ETA: 4s - loss: 0.0237 - acc: 0.992 - ETA: 4s - loss: 0.0237 - acc: 0.992 - ETA: 4s - loss: 0.0235 - acc: 0.992 - ETA: 4s - loss: 0.0234 - acc: 0.992 - ETA: 3s - loss: 0.0232 - acc: 0.993 - ETA: 3s - loss: 0.0232 - acc: 0.993 - ETA: 3s - loss: 0.0232 - acc: 0.993 - ETA: 3s - loss: 0.0232 - acc: 0.993 - ETA: 3s - loss: 0.0231 - acc: 0.993 - ETA: 3s - loss: 0.0231 - acc: 0.992 - ETA: 3s - loss: 0.0234 - acc: 0.992 - ETA: 3s - loss: 0.0233 - acc: 0.992 - ETA: 3s - loss: 0.0235 - acc: 0.992 - ETA: 3s - loss: 0.0235 - acc: 0.992 - ETA: 3s - loss: 0.0234 - acc: 0.992 - ETA: 3s - loss: 0.0234 - acc: 0.992 - ETA: 3s - loss: 0.0233 - acc: 0.992 - ETA: 3s - loss: 0.0232 - acc: 0.993 - ETA: 3s - loss: 0.0233 - acc: 0.992 - ETA: 3s - loss: 0.0233 - acc: 0.992 - ETA: 3s - loss: 0.0233 - acc: 0.992 - ETA: 3s - loss: 0.0234 - acc: 0.992 - ETA: 2s - loss: 0.0234 - acc: 0.992 - ETA: 2s - loss: 0.0233 - acc: 0.992 - ETA: 2s - loss: 0.0233 - acc: 0.992 - ETA: 2s - loss: 0.0233 - acc: 0.992 - ETA: 2s - loss: 0.0233 - acc: 0.992 - ETA: 2s - loss: 0.0233 - acc: 0.992 - ETA: 2s - loss: 0.0232 - acc: 0.992 - ETA: 2s - loss: 0.0231 - acc: 0.992 - ETA: 2s - loss: 0.0232 - acc: 0.992 - ETA: 2s - loss: 0.0233 - acc: 0.992 - ETA: 2s - loss: 0.0233 - acc: 0.992 - ETA: 2s - loss: 0.0233 - acc: 0.992 - ETA: 2s - loss: 0.0232 - acc: 0.992 - ETA: 2s - loss: 0.0231 - acc: 0.992 - ETA: 2s - loss: 0.0230 - acc: 0.992 - ETA: 2s - loss: 0.0230 - acc: 0.992 - ETA: 1s - loss: 0.0230 - acc: 0.992 - ETA: 1s - loss: 0.0229 - acc: 0.992 - ETA: 1s - loss: 0.0232 - acc: 0.992 - ETA: 1s - loss: 0.0231 - acc: 0.992 - ETA: 1s - loss: 0.0232 - acc: 0.992 - ETA: 1s - loss: 0.0231 - acc: 0.992 - ETA: 1s - loss: 0.0232 - acc: 0.992 - ETA: 1s - loss: 0.0231 - acc: 0.992 - ETA: 1s - loss: 0.0231 - acc: 0.992 - ETA: 1s - loss: 0.0230 - acc: 0.992 - ETA: 1s - loss: 0.0231 - acc: 0.992 - ETA: 1s - loss: 0.0231 - acc: 0.992 - ETA: 1s - loss: 0.0230 - acc: 0.992 - ETA: 1s - loss: 0.0230 - acc: 0.992 - ETA: 1s - loss: 0.0232 - acc: 0.992 - ETA: 1s - loss: 0.0233 - acc: 0.992 - ETA: 1s - loss: 0.0234 - acc: 0.992 - ETA: 1s - loss: 0.0234 - acc: 0.992 - ETA: 1s - loss: 0.0234 - acc: 0.992 - ETA: 0s - loss: 0.0238 - acc: 0.992 - ETA: 0s - loss: 0.0239 - acc: 0.992 - ETA: 0s - loss: 0.0238 - acc: 0.992 - ETA: 0s - loss: 0.0238 - acc: 0.992 - ETA: 0s - loss: 0.0238 - acc: 0.992 - ETA: 0s - loss: 0.0236 - acc: 0.992 - ETA: 0s - loss: 0.0236 - acc: 0.992 - ETA: 0s - loss: 0.0235 - acc: 0.992 - ETA: 0s - loss: 0.0235 - acc: 0.992 - ETA: 0s - loss: 0.0235 - acc: 0.992 - ETA: 0s - loss: 0.0234 - acc: 0.992 - ETA: 0s - loss: 0.0233 - acc: 0.992 - ETA: 0s - loss: 0.0233 - acc: 0.992 - ETA: 0s - loss: 0.0232 - acc: 0.992 - ETA: 0s - loss: 0.0231 - acc: 0.992 - ETA: 0s - loss: 0.0231 - acc: 0.992 - ETA: 0s - loss: 0.0232 - acc: 0.992 - 8s 165us/sample - loss: 0.0232 - acc: 0.9929 - val_loss: 0.0422 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00036247457473881936.\n",
      "Epoch 14/20\n",
      "49740/49740 [==============================] - ETA: 8s - loss: 0.0100 - acc: 1.000 - ETA: 8s - loss: 0.0134 - acc: 0.996 - ETA: 7s - loss: 0.0178 - acc: 0.995 - ETA: 7s - loss: 0.0251 - acc: 0.993 - ETA: 7s - loss: 0.0218 - acc: 0.994 - ETA: 7s - loss: 0.0190 - acc: 0.995 - ETA: 7s - loss: 0.0170 - acc: 0.995 - ETA: 7s - loss: 0.0191 - acc: 0.995 - ETA: 7s - loss: 0.0201 - acc: 0.995 - ETA: 7s - loss: 0.0190 - acc: 0.995 - ETA: 6s - loss: 0.0198 - acc: 0.995 - ETA: 6s - loss: 0.0198 - acc: 0.994 - ETA: 6s - loss: 0.0196 - acc: 0.994 - ETA: 6s - loss: 0.0197 - acc: 0.994 - ETA: 6s - loss: 0.0209 - acc: 0.994 - ETA: 7s - loss: 0.0202 - acc: 0.994 - ETA: 7s - loss: 0.0196 - acc: 0.994 - ETA: 7s - loss: 0.0195 - acc: 0.994 - ETA: 7s - loss: 0.0200 - acc: 0.994 - ETA: 6s - loss: 0.0195 - acc: 0.994 - ETA: 6s - loss: 0.0189 - acc: 0.995 - ETA: 6s - loss: 0.0198 - acc: 0.994 - ETA: 6s - loss: 0.0204 - acc: 0.994 - ETA: 6s - loss: 0.0203 - acc: 0.994 - ETA: 6s - loss: 0.0200 - acc: 0.994 - ETA: 6s - loss: 0.0200 - acc: 0.994 - ETA: 6s - loss: 0.0197 - acc: 0.994 - ETA: 6s - loss: 0.0199 - acc: 0.994 - ETA: 6s - loss: 0.0199 - acc: 0.994 - ETA: 6s - loss: 0.0199 - acc: 0.994 - ETA: 6s - loss: 0.0197 - acc: 0.994 - ETA: 5s - loss: 0.0194 - acc: 0.994 - ETA: 5s - loss: 0.0197 - acc: 0.994 - ETA: 5s - loss: 0.0196 - acc: 0.994 - ETA: 5s - loss: 0.0197 - acc: 0.994 - ETA: 5s - loss: 0.0202 - acc: 0.993 - ETA: 5s - loss: 0.0202 - acc: 0.993 - ETA: 5s - loss: 0.0200 - acc: 0.993 - ETA: 5s - loss: 0.0199 - acc: 0.993 - ETA: 5s - loss: 0.0204 - acc: 0.993 - ETA: 5s - loss: 0.0203 - acc: 0.993 - ETA: 5s - loss: 0.0203 - acc: 0.993 - ETA: 5s - loss: 0.0206 - acc: 0.993 - ETA: 5s - loss: 0.0209 - acc: 0.993 - ETA: 5s - loss: 0.0207 - acc: 0.993 - ETA: 4s - loss: 0.0207 - acc: 0.993 - ETA: 4s - loss: 0.0208 - acc: 0.993 - ETA: 4s - loss: 0.0206 - acc: 0.993 - ETA: 4s - loss: 0.0209 - acc: 0.993 - ETA: 4s - loss: 0.0211 - acc: 0.993 - ETA: 4s - loss: 0.0211 - acc: 0.993 - ETA: 4s - loss: 0.0209 - acc: 0.993 - ETA: 4s - loss: 0.0207 - acc: 0.993 - ETA: 4s - loss: 0.0207 - acc: 0.993 - ETA: 4s - loss: 0.0205 - acc: 0.993 - ETA: 4s - loss: 0.0205 - acc: 0.993 - ETA: 4s - loss: 0.0206 - acc: 0.993 - ETA: 4s - loss: 0.0204 - acc: 0.993 - ETA: 4s - loss: 0.0210 - acc: 0.993 - ETA: 4s - loss: 0.0209 - acc: 0.993 - ETA: 4s - loss: 0.0208 - acc: 0.993 - ETA: 4s - loss: 0.0207 - acc: 0.993 - ETA: 4s - loss: 0.0210 - acc: 0.993 - ETA: 3s - loss: 0.0211 - acc: 0.993 - ETA: 3s - loss: 0.0218 - acc: 0.993 - ETA: 3s - loss: 0.0219 - acc: 0.993 - ETA: 3s - loss: 0.0218 - acc: 0.993 - ETA: 3s - loss: 0.0220 - acc: 0.993 - ETA: 3s - loss: 0.0223 - acc: 0.993 - ETA: 3s - loss: 0.0223 - acc: 0.993 - ETA: 3s - loss: 0.0223 - acc: 0.993 - ETA: 3s - loss: 0.0224 - acc: 0.993 - ETA: 3s - loss: 0.0223 - acc: 0.993 - ETA: 3s - loss: 0.0222 - acc: 0.993 - ETA: 3s - loss: 0.0220 - acc: 0.993 - ETA: 3s - loss: 0.0219 - acc: 0.993 - ETA: 3s - loss: 0.0217 - acc: 0.993 - ETA: 3s - loss: 0.0219 - acc: 0.993 - ETA: 3s - loss: 0.0218 - acc: 0.993 - ETA: 3s - loss: 0.0217 - acc: 0.993 - ETA: 3s - loss: 0.0218 - acc: 0.993 - ETA: 2s - loss: 0.0217 - acc: 0.993 - ETA: 2s - loss: 0.0217 - acc: 0.993 - ETA: 2s - loss: 0.0216 - acc: 0.993 - ETA: 2s - loss: 0.0216 - acc: 0.993 - ETA: 2s - loss: 0.0218 - acc: 0.993 - ETA: 2s - loss: 0.0220 - acc: 0.993 - ETA: 2s - loss: 0.0218 - acc: 0.993 - ETA: 2s - loss: 0.0218 - acc: 0.993 - ETA: 2s - loss: 0.0219 - acc: 0.993 - ETA: 2s - loss: 0.0219 - acc: 0.993 - ETA: 2s - loss: 0.0218 - acc: 0.993 - ETA: 2s - loss: 0.0217 - acc: 0.993 - ETA: 2s - loss: 0.0217 - acc: 0.993 - ETA: 2s - loss: 0.0216 - acc: 0.993 - ETA: 2s - loss: 0.0215 - acc: 0.993 - ETA: 2s - loss: 0.0218 - acc: 0.993 - ETA: 2s - loss: 0.0216 - acc: 0.993 - ETA: 1s - loss: 0.0215 - acc: 0.993 - ETA: 1s - loss: 0.0214 - acc: 0.993 - ETA: 1s - loss: 0.0214 - acc: 0.993 - ETA: 1s - loss: 0.0213 - acc: 0.993 - ETA: 1s - loss: 0.0213 - acc: 0.993 - ETA: 1s - loss: 0.0212 - acc: 0.993 - ETA: 1s - loss: 0.0213 - acc: 0.993 - ETA: 1s - loss: 0.0214 - acc: 0.993 - ETA: 1s - loss: 0.0214 - acc: 0.993 - ETA: 1s - loss: 0.0214 - acc: 0.993 - ETA: 1s - loss: 0.0215 - acc: 0.993 - ETA: 1s - loss: 0.0214 - acc: 0.993 - ETA: 1s - loss: 0.0214 - acc: 0.993 - ETA: 1s - loss: 0.0215 - acc: 0.993 - ETA: 1s - loss: 0.0214 - acc: 0.993 - ETA: 1s - loss: 0.0214 - acc: 0.993 - ETA: 1s - loss: 0.0217 - acc: 0.993 - ETA: 1s - loss: 0.0218 - acc: 0.993 - ETA: 1s - loss: 0.0216 - acc: 0.993 - ETA: 0s - loss: 0.0216 - acc: 0.993 - ETA: 0s - loss: 0.0219 - acc: 0.993 - ETA: 0s - loss: 0.0218 - acc: 0.993 - ETA: 0s - loss: 0.0218 - acc: 0.993 - ETA: 0s - loss: 0.0217 - acc: 0.993 - ETA: 0s - loss: 0.0216 - acc: 0.993 - ETA: 0s - loss: 0.0216 - acc: 0.993 - ETA: 0s - loss: 0.0216 - acc: 0.993 - ETA: 0s - loss: 0.0216 - acc: 0.993 - ETA: 0s - loss: 0.0215 - acc: 0.993 - ETA: 0s - loss: 0.0214 - acc: 0.993 - ETA: 0s - loss: 0.0215 - acc: 0.993 - ETA: 0s - loss: 0.0214 - acc: 0.993 - ETA: 0s - loss: 0.0214 - acc: 0.993 - ETA: 0s - loss: 0.0213 - acc: 0.993 - ETA: 0s - loss: 0.0212 - acc: 0.993 - ETA: 0s - loss: 0.0211 - acc: 0.993 - 8s 160us/sample - loss: 0.0211 - acc: 0.9935 - val_loss: 0.0435 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.00028807125102990415.\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49740/49740 [==============================] - ETA: 8s - loss: 0.0116 - acc: 0.992 - ETA: 8s - loss: 0.0156 - acc: 0.994 - ETA: 8s - loss: 0.0333 - acc: 0.991 - ETA: 8s - loss: 0.0279 - acc: 0.993 - ETA: 8s - loss: 0.0288 - acc: 0.992 - ETA: 8s - loss: 0.0274 - acc: 0.992 - ETA: 8s - loss: 0.0261 - acc: 0.993 - ETA: 8s - loss: 0.0268 - acc: 0.992 - ETA: 8s - loss: 0.0257 - acc: 0.992 - ETA: 8s - loss: 0.0263 - acc: 0.992 - ETA: 8s - loss: 0.0249 - acc: 0.993 - ETA: 8s - loss: 0.0241 - acc: 0.993 - ETA: 7s - loss: 0.0230 - acc: 0.993 - ETA: 7s - loss: 0.0237 - acc: 0.993 - ETA: 7s - loss: 0.0230 - acc: 0.993 - ETA: 7s - loss: 0.0233 - acc: 0.993 - ETA: 7s - loss: 0.0224 - acc: 0.993 - ETA: 7s - loss: 0.0222 - acc: 0.993 - ETA: 7s - loss: 0.0223 - acc: 0.993 - ETA: 7s - loss: 0.0221 - acc: 0.993 - ETA: 7s - loss: 0.0220 - acc: 0.993 - ETA: 7s - loss: 0.0220 - acc: 0.993 - ETA: 7s - loss: 0.0221 - acc: 0.993 - ETA: 7s - loss: 0.0220 - acc: 0.993 - ETA: 7s - loss: 0.0228 - acc: 0.992 - ETA: 7s - loss: 0.0229 - acc: 0.992 - ETA: 7s - loss: 0.0229 - acc: 0.992 - ETA: 7s - loss: 0.0226 - acc: 0.992 - ETA: 7s - loss: 0.0227 - acc: 0.992 - ETA: 7s - loss: 0.0225 - acc: 0.992 - ETA: 6s - loss: 0.0224 - acc: 0.992 - ETA: 6s - loss: 0.0222 - acc: 0.992 - ETA: 6s - loss: 0.0226 - acc: 0.992 - ETA: 6s - loss: 0.0223 - acc: 0.992 - ETA: 6s - loss: 0.0221 - acc: 0.992 - ETA: 6s - loss: 0.0219 - acc: 0.992 - ETA: 6s - loss: 0.0217 - acc: 0.992 - ETA: 6s - loss: 0.0216 - acc: 0.993 - ETA: 6s - loss: 0.0216 - acc: 0.993 - ETA: 6s - loss: 0.0213 - acc: 0.993 - ETA: 6s - loss: 0.0213 - acc: 0.993 - ETA: 6s - loss: 0.0215 - acc: 0.993 - ETA: 6s - loss: 0.0225 - acc: 0.992 - ETA: 6s - loss: 0.0226 - acc: 0.992 - ETA: 5s - loss: 0.0223 - acc: 0.992 - ETA: 5s - loss: 0.0221 - acc: 0.993 - ETA: 5s - loss: 0.0220 - acc: 0.993 - ETA: 5s - loss: 0.0218 - acc: 0.993 - ETA: 5s - loss: 0.0220 - acc: 0.993 - ETA: 5s - loss: 0.0220 - acc: 0.992 - ETA: 5s - loss: 0.0220 - acc: 0.992 - ETA: 5s - loss: 0.0221 - acc: 0.992 - ETA: 5s - loss: 0.0221 - acc: 0.992 - ETA: 5s - loss: 0.0220 - acc: 0.992 - ETA: 5s - loss: 0.0224 - acc: 0.992 - ETA: 5s - loss: 0.0232 - acc: 0.992 - ETA: 5s - loss: 0.0230 - acc: 0.992 - ETA: 5s - loss: 0.0229 - acc: 0.992 - ETA: 5s - loss: 0.0229 - acc: 0.992 - ETA: 5s - loss: 0.0229 - acc: 0.992 - ETA: 5s - loss: 0.0229 - acc: 0.992 - ETA: 5s - loss: 0.0227 - acc: 0.992 - ETA: 5s - loss: 0.0225 - acc: 0.992 - ETA: 5s - loss: 0.0230 - acc: 0.992 - ETA: 4s - loss: 0.0229 - acc: 0.992 - ETA: 4s - loss: 0.0229 - acc: 0.992 - ETA: 4s - loss: 0.0228 - acc: 0.992 - ETA: 4s - loss: 0.0226 - acc: 0.992 - ETA: 4s - loss: 0.0233 - acc: 0.992 - ETA: 4s - loss: 0.0234 - acc: 0.992 - ETA: 4s - loss: 0.0232 - acc: 0.992 - ETA: 4s - loss: 0.0229 - acc: 0.992 - ETA: 4s - loss: 0.0228 - acc: 0.992 - ETA: 4s - loss: 0.0227 - acc: 0.992 - ETA: 4s - loss: 0.0230 - acc: 0.992 - ETA: 4s - loss: 0.0230 - acc: 0.992 - ETA: 4s - loss: 0.0229 - acc: 0.992 - ETA: 4s - loss: 0.0228 - acc: 0.992 - ETA: 4s - loss: 0.0226 - acc: 0.992 - ETA: 4s - loss: 0.0225 - acc: 0.992 - ETA: 4s - loss: 0.0227 - acc: 0.992 - ETA: 4s - loss: 0.0226 - acc: 0.992 - ETA: 4s - loss: 0.0224 - acc: 0.992 - ETA: 4s - loss: 0.0225 - acc: 0.992 - ETA: 3s - loss: 0.0227 - acc: 0.992 - ETA: 3s - loss: 0.0227 - acc: 0.992 - ETA: 3s - loss: 0.0227 - acc: 0.992 - ETA: 3s - loss: 0.0227 - acc: 0.992 - ETA: 3s - loss: 0.0226 - acc: 0.992 - ETA: 3s - loss: 0.0226 - acc: 0.992 - ETA: 3s - loss: 0.0225 - acc: 0.992 - ETA: 3s - loss: 0.0226 - acc: 0.992 - ETA: 3s - loss: 0.0225 - acc: 0.992 - ETA: 3s - loss: 0.0224 - acc: 0.992 - ETA: 3s - loss: 0.0223 - acc: 0.992 - ETA: 3s - loss: 0.0222 - acc: 0.992 - ETA: 3s - loss: 0.0222 - acc: 0.992 - ETA: 3s - loss: 0.0222 - acc: 0.992 - ETA: 3s - loss: 0.0222 - acc: 0.992 - ETA: 3s - loss: 0.0222 - acc: 0.992 - ETA: 3s - loss: 0.0222 - acc: 0.992 - ETA: 3s - loss: 0.0222 - acc: 0.992 - ETA: 3s - loss: 0.0222 - acc: 0.992 - ETA: 3s - loss: 0.0225 - acc: 0.992 - ETA: 2s - loss: 0.0224 - acc: 0.992 - ETA: 2s - loss: 0.0223 - acc: 0.992 - ETA: 2s - loss: 0.0221 - acc: 0.992 - ETA: 2s - loss: 0.0222 - acc: 0.992 - ETA: 2s - loss: 0.0221 - acc: 0.992 - ETA: 2s - loss: 0.0221 - acc: 0.992 - ETA: 2s - loss: 0.0221 - acc: 0.992 - ETA: 2s - loss: 0.0220 - acc: 0.992 - ETA: 2s - loss: 0.0219 - acc: 0.992 - ETA: 2s - loss: 0.0220 - acc: 0.992 - ETA: 2s - loss: 0.0219 - acc: 0.993 - ETA: 2s - loss: 0.0218 - acc: 0.993 - ETA: 2s - loss: 0.0220 - acc: 0.992 - ETA: 1s - loss: 0.0222 - acc: 0.992 - ETA: 1s - loss: 0.0223 - acc: 0.992 - ETA: 1s - loss: 0.0223 - acc: 0.992 - ETA: 1s - loss: 0.0222 - acc: 0.992 - ETA: 1s - loss: 0.0221 - acc: 0.992 - ETA: 1s - loss: 0.0220 - acc: 0.992 - ETA: 1s - loss: 0.0222 - acc: 0.992 - ETA: 1s - loss: 0.0222 - acc: 0.992 - ETA: 1s - loss: 0.0220 - acc: 0.992 - ETA: 1s - loss: 0.0221 - acc: 0.992 - ETA: 1s - loss: 0.0220 - acc: 0.992 - ETA: 1s - loss: 0.0220 - acc: 0.992 - ETA: 1s - loss: 0.0219 - acc: 0.993 - ETA: 1s - loss: 0.0219 - acc: 0.993 - ETA: 1s - loss: 0.0218 - acc: 0.993 - ETA: 0s - loss: 0.0217 - acc: 0.993 - ETA: 0s - loss: 0.0218 - acc: 0.993 - ETA: 0s - loss: 0.0219 - acc: 0.993 - ETA: 0s - loss: 0.0219 - acc: 0.993 - ETA: 0s - loss: 0.0218 - acc: 0.993 - ETA: 0s - loss: 0.0217 - acc: 0.993 - ETA: 0s - loss: 0.0217 - acc: 0.993 - ETA: 0s - loss: 0.0218 - acc: 0.993 - ETA: 0s - loss: 0.0217 - acc: 0.993 - ETA: 0s - loss: 0.0216 - acc: 0.993 - ETA: 0s - loss: 0.0217 - acc: 0.993 - ETA: 0s - loss: 0.0218 - acc: 0.993 - ETA: 0s - loss: 0.0219 - acc: 0.993 - ETA: 0s - loss: 0.0218 - acc: 0.993 - 9s 179us/sample - loss: 0.0218 - acc: 0.9929 - val_loss: 0.0417 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0002347589399817094.\n",
      "Epoch 16/20\n",
      "49740/49740 [==============================] - ETA: 8s - loss: 0.0395 - acc: 0.984 - ETA: 8s - loss: 0.0295 - acc: 0.990 - ETA: 8s - loss: 0.0490 - acc: 0.989 - ETA: 8s - loss: 0.0371 - acc: 0.993 - ETA: 9s - loss: 0.0346 - acc: 0.993 - ETA: 10s - loss: 0.0331 - acc: 0.99 - ETA: 10s - loss: 0.0304 - acc: 0.99 - ETA: 10s - loss: 0.0294 - acc: 0.99 - ETA: 11s - loss: 0.0293 - acc: 0.99 - ETA: 11s - loss: 0.0280 - acc: 0.99 - ETA: 11s - loss: 0.0256 - acc: 0.99 - ETA: 11s - loss: 0.0239 - acc: 0.99 - ETA: 11s - loss: 0.0239 - acc: 0.99 - ETA: 10s - loss: 0.0221 - acc: 0.99 - ETA: 10s - loss: 0.0218 - acc: 0.99 - ETA: 9s - loss: 0.0221 - acc: 0.9940 - ETA: 9s - loss: 0.0217 - acc: 0.993 - ETA: 9s - loss: 0.0211 - acc: 0.994 - ETA: 9s - loss: 0.0208 - acc: 0.994 - ETA: 8s - loss: 0.0201 - acc: 0.994 - ETA: 8s - loss: 0.0203 - acc: 0.994 - ETA: 8s - loss: 0.0198 - acc: 0.994 - ETA: 8s - loss: 0.0196 - acc: 0.994 - ETA: 8s - loss: 0.0194 - acc: 0.994 - ETA: 8s - loss: 0.0212 - acc: 0.994 - ETA: 8s - loss: 0.0207 - acc: 0.994 - ETA: 8s - loss: 0.0206 - acc: 0.994 - ETA: 8s - loss: 0.0211 - acc: 0.994 - ETA: 8s - loss: 0.0210 - acc: 0.994 - ETA: 7s - loss: 0.0208 - acc: 0.994 - ETA: 7s - loss: 0.0207 - acc: 0.994 - ETA: 7s - loss: 0.0214 - acc: 0.994 - ETA: 7s - loss: 0.0210 - acc: 0.994 - ETA: 7s - loss: 0.0214 - acc: 0.994 - ETA: 7s - loss: 0.0218 - acc: 0.994 - ETA: 7s - loss: 0.0217 - acc: 0.994 - ETA: 7s - loss: 0.0217 - acc: 0.994 - ETA: 6s - loss: 0.0215 - acc: 0.994 - ETA: 6s - loss: 0.0215 - acc: 0.994 - ETA: 6s - loss: 0.0215 - acc: 0.994 - ETA: 6s - loss: 0.0214 - acc: 0.993 - ETA: 6s - loss: 0.0217 - acc: 0.994 - ETA: 6s - loss: 0.0218 - acc: 0.993 - ETA: 6s - loss: 0.0214 - acc: 0.994 - ETA: 6s - loss: 0.0212 - acc: 0.994 - ETA: 6s - loss: 0.0212 - acc: 0.993 - ETA: 5s - loss: 0.0214 - acc: 0.993 - ETA: 5s - loss: 0.0215 - acc: 0.993 - ETA: 5s - loss: 0.0213 - acc: 0.993 - ETA: 5s - loss: 0.0212 - acc: 0.994 - ETA: 5s - loss: 0.0212 - acc: 0.994 - ETA: 5s - loss: 0.0214 - acc: 0.993 - ETA: 5s - loss: 0.0213 - acc: 0.993 - ETA: 5s - loss: 0.0215 - acc: 0.993 - ETA: 5s - loss: 0.0224 - acc: 0.993 - ETA: 5s - loss: 0.0224 - acc: 0.993 - ETA: 5s - loss: 0.0221 - acc: 0.993 - ETA: 5s - loss: 0.0220 - acc: 0.993 - ETA: 4s - loss: 0.0220 - acc: 0.993 - ETA: 4s - loss: 0.0220 - acc: 0.993 - ETA: 4s - loss: 0.0223 - acc: 0.993 - ETA: 4s - loss: 0.0221 - acc: 0.993 - ETA: 4s - loss: 0.0221 - acc: 0.993 - ETA: 4s - loss: 0.0221 - acc: 0.993 - ETA: 4s - loss: 0.0222 - acc: 0.993 - ETA: 4s - loss: 0.0220 - acc: 0.993 - ETA: 4s - loss: 0.0218 - acc: 0.993 - ETA: 4s - loss: 0.0218 - acc: 0.993 - ETA: 4s - loss: 0.0219 - acc: 0.993 - ETA: 4s - loss: 0.0218 - acc: 0.993 - ETA: 4s - loss: 0.0216 - acc: 0.993 - ETA: 4s - loss: 0.0215 - acc: 0.993 - ETA: 4s - loss: 0.0214 - acc: 0.993 - ETA: 3s - loss: 0.0213 - acc: 0.993 - ETA: 3s - loss: 0.0212 - acc: 0.993 - ETA: 3s - loss: 0.0210 - acc: 0.993 - ETA: 3s - loss: 0.0210 - acc: 0.993 - ETA: 3s - loss: 0.0211 - acc: 0.993 - ETA: 3s - loss: 0.0211 - acc: 0.993 - ETA: 3s - loss: 0.0211 - acc: 0.993 - ETA: 3s - loss: 0.0210 - acc: 0.993 - ETA: 3s - loss: 0.0209 - acc: 0.993 - ETA: 3s - loss: 0.0207 - acc: 0.993 - ETA: 3s - loss: 0.0206 - acc: 0.994 - ETA: 3s - loss: 0.0206 - acc: 0.994 - ETA: 3s - loss: 0.0206 - acc: 0.994 - ETA: 3s - loss: 0.0204 - acc: 0.994 - ETA: 3s - loss: 0.0203 - acc: 0.994 - ETA: 3s - loss: 0.0204 - acc: 0.994 - ETA: 3s - loss: 0.0204 - acc: 0.994 - ETA: 3s - loss: 0.0204 - acc: 0.994 - ETA: 2s - loss: 0.0203 - acc: 0.994 - ETA: 2s - loss: 0.0204 - acc: 0.994 - ETA: 2s - loss: 0.0204 - acc: 0.994 - ETA: 2s - loss: 0.0203 - acc: 0.994 - ETA: 2s - loss: 0.0202 - acc: 0.994 - ETA: 2s - loss: 0.0202 - acc: 0.994 - ETA: 2s - loss: 0.0201 - acc: 0.994 - ETA: 2s - loss: 0.0201 - acc: 0.994 - ETA: 2s - loss: 0.0200 - acc: 0.994 - ETA: 2s - loss: 0.0199 - acc: 0.994 - ETA: 2s - loss: 0.0198 - acc: 0.994 - ETA: 2s - loss: 0.0198 - acc: 0.994 - ETA: 2s - loss: 0.0198 - acc: 0.994 - ETA: 2s - loss: 0.0199 - acc: 0.994 - ETA: 2s - loss: 0.0200 - acc: 0.994 - ETA: 1s - loss: 0.0201 - acc: 0.994 - ETA: 1s - loss: 0.0201 - acc: 0.994 - ETA: 1s - loss: 0.0200 - acc: 0.994 - ETA: 1s - loss: 0.0200 - acc: 0.994 - ETA: 1s - loss: 0.0200 - acc: 0.994 - ETA: 1s - loss: 0.0200 - acc: 0.994 - ETA: 1s - loss: 0.0199 - acc: 0.994 - ETA: 1s - loss: 0.0199 - acc: 0.994 - ETA: 1s - loss: 0.0199 - acc: 0.994 - ETA: 1s - loss: 0.0200 - acc: 0.994 - ETA: 1s - loss: 0.0199 - acc: 0.994 - ETA: 1s - loss: 0.0199 - acc: 0.994 - ETA: 1s - loss: 0.0198 - acc: 0.994 - ETA: 1s - loss: 0.0199 - acc: 0.993 - ETA: 1s - loss: 0.0200 - acc: 0.993 - ETA: 1s - loss: 0.0199 - acc: 0.993 - ETA: 0s - loss: 0.0199 - acc: 0.993 - ETA: 0s - loss: 0.0199 - acc: 0.993 - ETA: 0s - loss: 0.0199 - acc: 0.993 - ETA: 0s - loss: 0.0198 - acc: 0.993 - ETA: 0s - loss: 0.0198 - acc: 0.994 - ETA: 0s - loss: 0.0199 - acc: 0.993 - ETA: 0s - loss: 0.0199 - acc: 0.993 - ETA: 0s - loss: 0.0199 - acc: 0.993 - ETA: 0s - loss: 0.0197 - acc: 0.993 - ETA: 0s - loss: 0.0197 - acc: 0.993 - ETA: 0s - loss: 0.0197 - acc: 0.993 - ETA: 0s - loss: 0.0197 - acc: 0.993 - ETA: 0s - loss: 0.0197 - acc: 0.994 - ETA: 0s - loss: 0.0197 - acc: 0.993 - ETA: 0s - loss: 0.0197 - acc: 0.993 - 9s 171us/sample - loss: 0.0197 - acc: 0.9939 - val_loss: 0.0402 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00019655899987662886.\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49740/49740 [==============================] - ETA: 11s - loss: 0.0173 - acc: 0.99 - ETA: 11s - loss: 0.0087 - acc: 0.99 - ETA: 10s - loss: 0.0129 - acc: 0.99 - ETA: 10s - loss: 0.0148 - acc: 0.99 - ETA: 10s - loss: 0.0136 - acc: 0.99 - ETA: 10s - loss: 0.0150 - acc: 0.99 - ETA: 10s - loss: 0.0199 - acc: 0.99 - ETA: 10s - loss: 0.0205 - acc: 0.99 - ETA: 9s - loss: 0.0190 - acc: 0.9937 - ETA: 9s - loss: 0.0197 - acc: 0.992 - ETA: 9s - loss: 0.0187 - acc: 0.993 - ETA: 9s - loss: 0.0182 - acc: 0.993 - ETA: 9s - loss: 0.0184 - acc: 0.993 - ETA: 9s - loss: 0.0183 - acc: 0.993 - ETA: 9s - loss: 0.0186 - acc: 0.993 - ETA: 9s - loss: 0.0185 - acc: 0.993 - ETA: 9s - loss: 0.0174 - acc: 0.994 - ETA: 8s - loss: 0.0175 - acc: 0.994 - ETA: 8s - loss: 0.0168 - acc: 0.994 - ETA: 8s - loss: 0.0173 - acc: 0.994 - ETA: 8s - loss: 0.0169 - acc: 0.994 - ETA: 8s - loss: 0.0171 - acc: 0.994 - ETA: 8s - loss: 0.0173 - acc: 0.994 - ETA: 7s - loss: 0.0170 - acc: 0.994 - ETA: 7s - loss: 0.0169 - acc: 0.994 - ETA: 7s - loss: 0.0178 - acc: 0.994 - ETA: 7s - loss: 0.0178 - acc: 0.994 - ETA: 7s - loss: 0.0176 - acc: 0.994 - ETA: 7s - loss: 0.0177 - acc: 0.994 - ETA: 7s - loss: 0.0174 - acc: 0.994 - ETA: 7s - loss: 0.0173 - acc: 0.994 - ETA: 6s - loss: 0.0171 - acc: 0.994 - ETA: 6s - loss: 0.0172 - acc: 0.994 - ETA: 6s - loss: 0.0172 - acc: 0.994 - ETA: 6s - loss: 0.0168 - acc: 0.994 - ETA: 6s - loss: 0.0170 - acc: 0.994 - ETA: 6s - loss: 0.0169 - acc: 0.994 - ETA: 6s - loss: 0.0168 - acc: 0.994 - ETA: 6s - loss: 0.0168 - acc: 0.994 - ETA: 6s - loss: 0.0175 - acc: 0.994 - ETA: 6s - loss: 0.0174 - acc: 0.994 - ETA: 6s - loss: 0.0173 - acc: 0.994 - ETA: 5s - loss: 0.0171 - acc: 0.994 - ETA: 5s - loss: 0.0175 - acc: 0.994 - ETA: 5s - loss: 0.0172 - acc: 0.994 - ETA: 5s - loss: 0.0172 - acc: 0.994 - ETA: 5s - loss: 0.0172 - acc: 0.994 - ETA: 5s - loss: 0.0174 - acc: 0.994 - ETA: 5s - loss: 0.0178 - acc: 0.994 - ETA: 5s - loss: 0.0182 - acc: 0.994 - ETA: 5s - loss: 0.0182 - acc: 0.994 - ETA: 5s - loss: 0.0185 - acc: 0.994 - ETA: 5s - loss: 0.0187 - acc: 0.993 - ETA: 5s - loss: 0.0187 - acc: 0.993 - ETA: 5s - loss: 0.0189 - acc: 0.993 - ETA: 4s - loss: 0.0197 - acc: 0.993 - ETA: 4s - loss: 0.0198 - acc: 0.993 - ETA: 4s - loss: 0.0201 - acc: 0.993 - ETA: 4s - loss: 0.0203 - acc: 0.993 - ETA: 4s - loss: 0.0202 - acc: 0.993 - ETA: 4s - loss: 0.0201 - acc: 0.993 - ETA: 4s - loss: 0.0199 - acc: 0.993 - ETA: 4s - loss: 0.0198 - acc: 0.993 - ETA: 4s - loss: 0.0204 - acc: 0.993 - ETA: 4s - loss: 0.0204 - acc: 0.993 - ETA: 4s - loss: 0.0203 - acc: 0.993 - ETA: 4s - loss: 0.0204 - acc: 0.993 - ETA: 4s - loss: 0.0202 - acc: 0.993 - ETA: 4s - loss: 0.0202 - acc: 0.993 - ETA: 4s - loss: 0.0203 - acc: 0.993 - ETA: 3s - loss: 0.0203 - acc: 0.993 - ETA: 3s - loss: 0.0203 - acc: 0.993 - ETA: 3s - loss: 0.0204 - acc: 0.993 - ETA: 3s - loss: 0.0203 - acc: 0.993 - ETA: 3s - loss: 0.0203 - acc: 0.993 - ETA: 3s - loss: 0.0203 - acc: 0.993 - ETA: 3s - loss: 0.0202 - acc: 0.993 - ETA: 3s - loss: 0.0201 - acc: 0.993 - ETA: 3s - loss: 0.0199 - acc: 0.993 - ETA: 3s - loss: 0.0198 - acc: 0.993 - ETA: 3s - loss: 0.0198 - acc: 0.993 - ETA: 3s - loss: 0.0198 - acc: 0.993 - ETA: 3s - loss: 0.0197 - acc: 0.993 - ETA: 3s - loss: 0.0197 - acc: 0.993 - ETA: 3s - loss: 0.0195 - acc: 0.993 - ETA: 3s - loss: 0.0194 - acc: 0.993 - ETA: 3s - loss: 0.0193 - acc: 0.993 - ETA: 3s - loss: 0.0192 - acc: 0.993 - ETA: 3s - loss: 0.0194 - acc: 0.993 - ETA: 3s - loss: 0.0192 - acc: 0.993 - ETA: 3s - loss: 0.0192 - acc: 0.993 - ETA: 2s - loss: 0.0191 - acc: 0.993 - ETA: 2s - loss: 0.0193 - acc: 0.993 - ETA: 2s - loss: 0.0194 - acc: 0.993 - ETA: 2s - loss: 0.0193 - acc: 0.993 - ETA: 2s - loss: 0.0193 - acc: 0.993 - ETA: 2s - loss: 0.0193 - acc: 0.993 - ETA: 2s - loss: 0.0192 - acc: 0.993 - ETA: 2s - loss: 0.0191 - acc: 0.993 - ETA: 2s - loss: 0.0190 - acc: 0.993 - ETA: 2s - loss: 0.0190 - acc: 0.993 - ETA: 2s - loss: 0.0190 - acc: 0.993 - ETA: 2s - loss: 0.0189 - acc: 0.994 - ETA: 2s - loss: 0.0188 - acc: 0.994 - ETA: 2s - loss: 0.0188 - acc: 0.994 - ETA: 2s - loss: 0.0190 - acc: 0.994 - ETA: 2s - loss: 0.0190 - acc: 0.994 - ETA: 1s - loss: 0.0195 - acc: 0.993 - ETA: 1s - loss: 0.0195 - acc: 0.994 - ETA: 1s - loss: 0.0195 - acc: 0.993 - ETA: 1s - loss: 0.0195 - acc: 0.993 - ETA: 1s - loss: 0.0194 - acc: 0.993 - ETA: 1s - loss: 0.0194 - acc: 0.994 - ETA: 1s - loss: 0.0194 - acc: 0.994 - ETA: 1s - loss: 0.0193 - acc: 0.994 - ETA: 1s - loss: 0.0193 - acc: 0.994 - ETA: 1s - loss: 0.0192 - acc: 0.994 - ETA: 1s - loss: 0.0194 - acc: 0.994 - ETA: 1s - loss: 0.0194 - acc: 0.994 - ETA: 1s - loss: 0.0193 - acc: 0.994 - ETA: 1s - loss: 0.0192 - acc: 0.994 - ETA: 1s - loss: 0.0192 - acc: 0.994 - ETA: 0s - loss: 0.0192 - acc: 0.994 - ETA: 0s - loss: 0.0192 - acc: 0.994 - ETA: 0s - loss: 0.0190 - acc: 0.994 - ETA: 0s - loss: 0.0195 - acc: 0.994 - ETA: 0s - loss: 0.0194 - acc: 0.994 - ETA: 0s - loss: 0.0194 - acc: 0.994 - ETA: 0s - loss: 0.0194 - acc: 0.994 - ETA: 0s - loss: 0.0195 - acc: 0.994 - ETA: 0s - loss: 0.0194 - acc: 0.994 - ETA: 0s - loss: 0.0193 - acc: 0.994 - ETA: 0s - loss: 0.0194 - acc: 0.994 - ETA: 0s - loss: 0.0194 - acc: 0.994 - ETA: 0s - loss: 0.0194 - acc: 0.994 - ETA: 0s - loss: 0.0195 - acc: 0.994 - ETA: 0s - loss: 0.0195 - acc: 0.994 - 8s 165us/sample - loss: 0.0194 - acc: 0.9940 - val_loss: 0.0402 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0001691875467292952.\n",
      "Epoch 18/20\n",
      "49740/49740 [==============================] - ETA: 6s - loss: 0.0039 - acc: 1.000 - ETA: 6s - loss: 0.0208 - acc: 0.994 - ETA: 6s - loss: 0.0247 - acc: 0.992 - ETA: 6s - loss: 0.0310 - acc: 0.993 - ETA: 6s - loss: 0.0305 - acc: 0.992 - ETA: 6s - loss: 0.0257 - acc: 0.993 - ETA: 6s - loss: 0.0232 - acc: 0.994 - ETA: 6s - loss: 0.0214 - acc: 0.994 - ETA: 6s - loss: 0.0220 - acc: 0.994 - ETA: 6s - loss: 0.0213 - acc: 0.994 - ETA: 6s - loss: 0.0214 - acc: 0.994 - ETA: 6s - loss: 0.0214 - acc: 0.994 - ETA: 6s - loss: 0.0205 - acc: 0.994 - ETA: 6s - loss: 0.0200 - acc: 0.994 - ETA: 5s - loss: 0.0209 - acc: 0.994 - ETA: 5s - loss: 0.0205 - acc: 0.994 - ETA: 5s - loss: 0.0208 - acc: 0.993 - ETA: 5s - loss: 0.0199 - acc: 0.994 - ETA: 5s - loss: 0.0197 - acc: 0.994 - ETA: 5s - loss: 0.0205 - acc: 0.993 - ETA: 5s - loss: 0.0200 - acc: 0.994 - ETA: 5s - loss: 0.0198 - acc: 0.994 - ETA: 5s - loss: 0.0205 - acc: 0.994 - ETA: 5s - loss: 0.0217 - acc: 0.994 - ETA: 5s - loss: 0.0216 - acc: 0.994 - ETA: 5s - loss: 0.0212 - acc: 0.994 - ETA: 5s - loss: 0.0210 - acc: 0.994 - ETA: 5s - loss: 0.0212 - acc: 0.994 - ETA: 5s - loss: 0.0211 - acc: 0.993 - ETA: 5s - loss: 0.0205 - acc: 0.994 - ETA: 5s - loss: 0.0200 - acc: 0.994 - ETA: 5s - loss: 0.0199 - acc: 0.994 - ETA: 5s - loss: 0.0195 - acc: 0.994 - ETA: 4s - loss: 0.0195 - acc: 0.994 - ETA: 4s - loss: 0.0191 - acc: 0.994 - ETA: 4s - loss: 0.0190 - acc: 0.994 - ETA: 4s - loss: 0.0186 - acc: 0.994 - ETA: 4s - loss: 0.0185 - acc: 0.994 - ETA: 4s - loss: 0.0185 - acc: 0.994 - ETA: 4s - loss: 0.0185 - acc: 0.994 - ETA: 4s - loss: 0.0183 - acc: 0.994 - ETA: 4s - loss: 0.0186 - acc: 0.994 - ETA: 4s - loss: 0.0186 - acc: 0.994 - ETA: 4s - loss: 0.0195 - acc: 0.994 - ETA: 4s - loss: 0.0195 - acc: 0.994 - ETA: 4s - loss: 0.0194 - acc: 0.994 - ETA: 4s - loss: 0.0195 - acc: 0.994 - ETA: 4s - loss: 0.0194 - acc: 0.994 - ETA: 4s - loss: 0.0193 - acc: 0.994 - ETA: 4s - loss: 0.0193 - acc: 0.994 - ETA: 4s - loss: 0.0198 - acc: 0.994 - ETA: 4s - loss: 0.0196 - acc: 0.994 - ETA: 4s - loss: 0.0198 - acc: 0.994 - ETA: 3s - loss: 0.0197 - acc: 0.994 - ETA: 3s - loss: 0.0197 - acc: 0.994 - ETA: 3s - loss: 0.0198 - acc: 0.994 - ETA: 3s - loss: 0.0197 - acc: 0.994 - ETA: 3s - loss: 0.0196 - acc: 0.994 - ETA: 3s - loss: 0.0196 - acc: 0.994 - ETA: 3s - loss: 0.0199 - acc: 0.994 - ETA: 3s - loss: 0.0199 - acc: 0.994 - ETA: 3s - loss: 0.0198 - acc: 0.994 - ETA: 3s - loss: 0.0197 - acc: 0.994 - ETA: 3s - loss: 0.0196 - acc: 0.994 - ETA: 3s - loss: 0.0194 - acc: 0.994 - ETA: 3s - loss: 0.0194 - acc: 0.994 - ETA: 3s - loss: 0.0192 - acc: 0.994 - ETA: 3s - loss: 0.0191 - acc: 0.994 - ETA: 3s - loss: 0.0192 - acc: 0.994 - ETA: 3s - loss: 0.0192 - acc: 0.994 - ETA: 3s - loss: 0.0191 - acc: 0.994 - ETA: 2s - loss: 0.0190 - acc: 0.994 - ETA: 2s - loss: 0.0190 - acc: 0.994 - ETA: 2s - loss: 0.0189 - acc: 0.994 - ETA: 2s - loss: 0.0191 - acc: 0.994 - ETA: 2s - loss: 0.0191 - acc: 0.994 - ETA: 2s - loss: 0.0192 - acc: 0.994 - ETA: 2s - loss: 0.0190 - acc: 0.994 - ETA: 2s - loss: 0.0190 - acc: 0.994 - ETA: 2s - loss: 0.0191 - acc: 0.994 - ETA: 2s - loss: 0.0190 - acc: 0.994 - ETA: 2s - loss: 0.0190 - acc: 0.994 - ETA: 2s - loss: 0.0189 - acc: 0.994 - ETA: 2s - loss: 0.0189 - acc: 0.994 - ETA: 2s - loss: 0.0187 - acc: 0.994 - ETA: 2s - loss: 0.0188 - acc: 0.994 - ETA: 2s - loss: 0.0187 - acc: 0.994 - ETA: 2s - loss: 0.0187 - acc: 0.994 - ETA: 2s - loss: 0.0186 - acc: 0.994 - ETA: 1s - loss: 0.0187 - acc: 0.994 - ETA: 1s - loss: 0.0186 - acc: 0.994 - ETA: 1s - loss: 0.0190 - acc: 0.994 - ETA: 1s - loss: 0.0190 - acc: 0.994 - ETA: 1s - loss: 0.0188 - acc: 0.994 - ETA: 1s - loss: 0.0190 - acc: 0.994 - ETA: 1s - loss: 0.0191 - acc: 0.994 - ETA: 1s - loss: 0.0191 - acc: 0.994 - ETA: 1s - loss: 0.0192 - acc: 0.994 - ETA: 1s - loss: 0.0191 - acc: 0.994 - ETA: 1s - loss: 0.0195 - acc: 0.994 - ETA: 1s - loss: 0.0195 - acc: 0.994 - ETA: 1s - loss: 0.0195 - acc: 0.994 - ETA: 1s - loss: 0.0194 - acc: 0.994 - ETA: 1s - loss: 0.0194 - acc: 0.994 - ETA: 1s - loss: 0.0194 - acc: 0.994 - ETA: 1s - loss: 0.0193 - acc: 0.994 - ETA: 1s - loss: 0.0194 - acc: 0.994 - ETA: 0s - loss: 0.0193 - acc: 0.994 - ETA: 0s - loss: 0.0194 - acc: 0.994 - ETA: 0s - loss: 0.0196 - acc: 0.994 - ETA: 0s - loss: 0.0195 - acc: 0.994 - ETA: 0s - loss: 0.0195 - acc: 0.994 - ETA: 0s - loss: 0.0194 - acc: 0.994 - ETA: 0s - loss: 0.0194 - acc: 0.994 - ETA: 0s - loss: 0.0198 - acc: 0.994 - ETA: 0s - loss: 0.0197 - acc: 0.994 - ETA: 0s - loss: 0.0197 - acc: 0.994 - ETA: 0s - loss: 0.0196 - acc: 0.994 - ETA: 0s - loss: 0.0195 - acc: 0.994 - ETA: 0s - loss: 0.0195 - acc: 0.994 - ETA: 0s - loss: 0.0196 - acc: 0.994 - ETA: 0s - loss: 0.0195 - acc: 0.994 - ETA: 0s - loss: 0.0196 - acc: 0.994 - ETA: 0s - loss: 0.0197 - acc: 0.994 - ETA: 0s - loss: 0.0197 - acc: 0.994 - ETA: 0s - loss: 0.0197 - acc: 0.994 - ETA: 0s - loss: 0.0197 - acc: 0.994 - 7s 140us/sample - loss: 0.0198 - acc: 0.9941 - val_loss: 0.0401 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0001495750435333272.\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49740/49740 [==============================] - ETA: 6s - loss: 0.0123 - acc: 1.000 - ETA: 6s - loss: 0.0186 - acc: 0.996 - ETA: 6s - loss: 0.0186 - acc: 0.996 - ETA: 6s - loss: 0.0181 - acc: 0.996 - ETA: 6s - loss: 0.0169 - acc: 0.996 - ETA: 6s - loss: 0.0161 - acc: 0.996 - ETA: 6s - loss: 0.0173 - acc: 0.996 - ETA: 6s - loss: 0.0171 - acc: 0.995 - ETA: 6s - loss: 0.0180 - acc: 0.995 - ETA: 6s - loss: 0.0182 - acc: 0.994 - ETA: 6s - loss: 0.0177 - acc: 0.994 - ETA: 6s - loss: 0.0170 - acc: 0.994 - ETA: 5s - loss: 0.0172 - acc: 0.994 - ETA: 5s - loss: 0.0168 - acc: 0.994 - ETA: 5s - loss: 0.0165 - acc: 0.994 - ETA: 5s - loss: 0.0181 - acc: 0.994 - ETA: 5s - loss: 0.0188 - acc: 0.994 - ETA: 5s - loss: 0.0185 - acc: 0.994 - ETA: 5s - loss: 0.0184 - acc: 0.994 - ETA: 5s - loss: 0.0184 - acc: 0.994 - ETA: 5s - loss: 0.0184 - acc: 0.994 - ETA: 5s - loss: 0.0179 - acc: 0.995 - ETA: 5s - loss: 0.0177 - acc: 0.995 - ETA: 5s - loss: 0.0177 - acc: 0.995 - ETA: 5s - loss: 0.0179 - acc: 0.994 - ETA: 5s - loss: 0.0174 - acc: 0.995 - ETA: 5s - loss: 0.0182 - acc: 0.994 - ETA: 5s - loss: 0.0179 - acc: 0.994 - ETA: 5s - loss: 0.0178 - acc: 0.994 - ETA: 5s - loss: 0.0180 - acc: 0.994 - ETA: 5s - loss: 0.0182 - acc: 0.994 - ETA: 4s - loss: 0.0180 - acc: 0.994 - ETA: 4s - loss: 0.0182 - acc: 0.994 - ETA: 4s - loss: 0.0181 - acc: 0.994 - ETA: 4s - loss: 0.0181 - acc: 0.994 - ETA: 4s - loss: 0.0180 - acc: 0.994 - ETA: 4s - loss: 0.0178 - acc: 0.994 - ETA: 4s - loss: 0.0175 - acc: 0.994 - ETA: 4s - loss: 0.0174 - acc: 0.994 - ETA: 4s - loss: 0.0174 - acc: 0.994 - ETA: 4s - loss: 0.0178 - acc: 0.994 - ETA: 4s - loss: 0.0180 - acc: 0.994 - ETA: 4s - loss: 0.0178 - acc: 0.994 - ETA: 4s - loss: 0.0179 - acc: 0.994 - ETA: 4s - loss: 0.0182 - acc: 0.994 - ETA: 4s - loss: 0.0181 - acc: 0.994 - ETA: 4s - loss: 0.0180 - acc: 0.994 - ETA: 4s - loss: 0.0180 - acc: 0.994 - ETA: 4s - loss: 0.0179 - acc: 0.994 - ETA: 4s - loss: 0.0178 - acc: 0.994 - ETA: 4s - loss: 0.0180 - acc: 0.994 - ETA: 3s - loss: 0.0180 - acc: 0.994 - ETA: 3s - loss: 0.0181 - acc: 0.994 - ETA: 3s - loss: 0.0179 - acc: 0.994 - ETA: 3s - loss: 0.0179 - acc: 0.994 - ETA: 3s - loss: 0.0179 - acc: 0.994 - ETA: 3s - loss: 0.0178 - acc: 0.994 - ETA: 3s - loss: 0.0177 - acc: 0.994 - ETA: 3s - loss: 0.0177 - acc: 0.994 - ETA: 3s - loss: 0.0176 - acc: 0.994 - ETA: 3s - loss: 0.0176 - acc: 0.994 - ETA: 3s - loss: 0.0176 - acc: 0.994 - ETA: 3s - loss: 0.0178 - acc: 0.994 - ETA: 3s - loss: 0.0178 - acc: 0.994 - ETA: 3s - loss: 0.0185 - acc: 0.994 - ETA: 3s - loss: 0.0184 - acc: 0.994 - ETA: 3s - loss: 0.0188 - acc: 0.994 - ETA: 3s - loss: 0.0190 - acc: 0.994 - ETA: 3s - loss: 0.0189 - acc: 0.994 - ETA: 2s - loss: 0.0189 - acc: 0.994 - ETA: 2s - loss: 0.0188 - acc: 0.994 - ETA: 2s - loss: 0.0189 - acc: 0.994 - ETA: 2s - loss: 0.0189 - acc: 0.994 - ETA: 2s - loss: 0.0188 - acc: 0.994 - ETA: 2s - loss: 0.0188 - acc: 0.994 - ETA: 2s - loss: 0.0187 - acc: 0.994 - ETA: 2s - loss: 0.0186 - acc: 0.994 - ETA: 2s - loss: 0.0185 - acc: 0.994 - ETA: 2s - loss: 0.0185 - acc: 0.994 - ETA: 2s - loss: 0.0185 - acc: 0.994 - ETA: 2s - loss: 0.0186 - acc: 0.994 - ETA: 2s - loss: 0.0192 - acc: 0.994 - ETA: 2s - loss: 0.0191 - acc: 0.994 - ETA: 2s - loss: 0.0190 - acc: 0.994 - ETA: 2s - loss: 0.0189 - acc: 0.994 - ETA: 2s - loss: 0.0189 - acc: 0.994 - ETA: 2s - loss: 0.0188 - acc: 0.994 - ETA: 2s - loss: 0.0188 - acc: 0.994 - ETA: 2s - loss: 0.0188 - acc: 0.994 - ETA: 1s - loss: 0.0188 - acc: 0.994 - ETA: 1s - loss: 0.0187 - acc: 0.994 - ETA: 1s - loss: 0.0187 - acc: 0.994 - ETA: 1s - loss: 0.0188 - acc: 0.994 - ETA: 1s - loss: 0.0188 - acc: 0.994 - ETA: 1s - loss: 0.0187 - acc: 0.994 - ETA: 1s - loss: 0.0187 - acc: 0.994 - ETA: 1s - loss: 0.0187 - acc: 0.994 - ETA: 1s - loss: 0.0189 - acc: 0.994 - ETA: 1s - loss: 0.0189 - acc: 0.994 - ETA: 1s - loss: 0.0188 - acc: 0.994 - ETA: 1s - loss: 0.0188 - acc: 0.994 - ETA: 1s - loss: 0.0187 - acc: 0.994 - ETA: 1s - loss: 0.0186 - acc: 0.994 - ETA: 1s - loss: 0.0185 - acc: 0.994 - ETA: 1s - loss: 0.0184 - acc: 0.994 - ETA: 1s - loss: 0.0183 - acc: 0.994 - ETA: 1s - loss: 0.0184 - acc: 0.994 - ETA: 1s - loss: 0.0183 - acc: 0.994 - ETA: 0s - loss: 0.0184 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0186 - acc: 0.994 - ETA: 0s - loss: 0.0186 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0186 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0186 - acc: 0.994 - 7s 138us/sample - loss: 0.0186 - acc: 0.9943 - val_loss: 0.0407 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0001355220709146876.\n",
      "Epoch 20/20\n",
      "49740/49740 [==============================] - ETA: 6s - loss: 0.0199 - acc: 0.992 - ETA: 6s - loss: 0.0178 - acc: 0.996 - ETA: 6s - loss: 0.0150 - acc: 0.996 - ETA: 6s - loss: 0.0167 - acc: 0.994 - ETA: 6s - loss: 0.0160 - acc: 0.995 - ETA: 6s - loss: 0.0170 - acc: 0.994 - ETA: 6s - loss: 0.0150 - acc: 0.995 - ETA: 6s - loss: 0.0154 - acc: 0.995 - ETA: 6s - loss: 0.0153 - acc: 0.994 - ETA: 6s - loss: 0.0168 - acc: 0.994 - ETA: 6s - loss: 0.0165 - acc: 0.994 - ETA: 6s - loss: 0.0162 - acc: 0.994 - ETA: 5s - loss: 0.0161 - acc: 0.994 - ETA: 5s - loss: 0.0164 - acc: 0.994 - ETA: 5s - loss: 0.0176 - acc: 0.994 - ETA: 5s - loss: 0.0181 - acc: 0.994 - ETA: 5s - loss: 0.0175 - acc: 0.994 - ETA: 5s - loss: 0.0183 - acc: 0.994 - ETA: 5s - loss: 0.0189 - acc: 0.994 - ETA: 5s - loss: 0.0186 - acc: 0.994 - ETA: 5s - loss: 0.0183 - acc: 0.994 - ETA: 5s - loss: 0.0179 - acc: 0.994 - ETA: 5s - loss: 0.0175 - acc: 0.994 - ETA: 5s - loss: 0.0171 - acc: 0.995 - ETA: 5s - loss: 0.0173 - acc: 0.995 - ETA: 5s - loss: 0.0172 - acc: 0.994 - ETA: 5s - loss: 0.0169 - acc: 0.995 - ETA: 5s - loss: 0.0179 - acc: 0.994 - ETA: 5s - loss: 0.0192 - acc: 0.994 - ETA: 5s - loss: 0.0185 - acc: 0.994 - ETA: 4s - loss: 0.0188 - acc: 0.994 - ETA: 4s - loss: 0.0188 - acc: 0.994 - ETA: 4s - loss: 0.0187 - acc: 0.994 - ETA: 4s - loss: 0.0183 - acc: 0.995 - ETA: 4s - loss: 0.0183 - acc: 0.994 - ETA: 4s - loss: 0.0181 - acc: 0.995 - ETA: 4s - loss: 0.0179 - acc: 0.995 - ETA: 4s - loss: 0.0179 - acc: 0.995 - ETA: 4s - loss: 0.0178 - acc: 0.995 - ETA: 4s - loss: 0.0179 - acc: 0.995 - ETA: 4s - loss: 0.0178 - acc: 0.995 - ETA: 4s - loss: 0.0176 - acc: 0.995 - ETA: 4s - loss: 0.0177 - acc: 0.995 - ETA: 4s - loss: 0.0179 - acc: 0.994 - ETA: 4s - loss: 0.0180 - acc: 0.994 - ETA: 4s - loss: 0.0178 - acc: 0.994 - ETA: 4s - loss: 0.0177 - acc: 0.994 - ETA: 4s - loss: 0.0176 - acc: 0.994 - ETA: 4s - loss: 0.0180 - acc: 0.994 - ETA: 3s - loss: 0.0180 - acc: 0.994 - ETA: 3s - loss: 0.0181 - acc: 0.994 - ETA: 3s - loss: 0.0179 - acc: 0.994 - ETA: 3s - loss: 0.0178 - acc: 0.994 - ETA: 3s - loss: 0.0177 - acc: 0.994 - ETA: 3s - loss: 0.0175 - acc: 0.994 - ETA: 3s - loss: 0.0176 - acc: 0.994 - ETA: 3s - loss: 0.0178 - acc: 0.994 - ETA: 3s - loss: 0.0176 - acc: 0.994 - ETA: 3s - loss: 0.0176 - acc: 0.994 - ETA: 3s - loss: 0.0175 - acc: 0.994 - ETA: 3s - loss: 0.0174 - acc: 0.994 - ETA: 3s - loss: 0.0175 - acc: 0.994 - ETA: 3s - loss: 0.0175 - acc: 0.994 - ETA: 3s - loss: 0.0180 - acc: 0.994 - ETA: 3s - loss: 0.0178 - acc: 0.994 - ETA: 3s - loss: 0.0180 - acc: 0.994 - ETA: 3s - loss: 0.0180 - acc: 0.994 - ETA: 3s - loss: 0.0181 - acc: 0.994 - ETA: 2s - loss: 0.0179 - acc: 0.994 - ETA: 2s - loss: 0.0179 - acc: 0.994 - ETA: 2s - loss: 0.0178 - acc: 0.994 - ETA: 2s - loss: 0.0177 - acc: 0.994 - ETA: 2s - loss: 0.0177 - acc: 0.994 - ETA: 2s - loss: 0.0176 - acc: 0.994 - ETA: 2s - loss: 0.0176 - acc: 0.994 - ETA: 2s - loss: 0.0175 - acc: 0.994 - ETA: 2s - loss: 0.0175 - acc: 0.994 - ETA: 2s - loss: 0.0175 - acc: 0.994 - ETA: 2s - loss: 0.0175 - acc: 0.994 - ETA: 2s - loss: 0.0176 - acc: 0.994 - ETA: 2s - loss: 0.0177 - acc: 0.994 - ETA: 2s - loss: 0.0177 - acc: 0.994 - ETA: 2s - loss: 0.0177 - acc: 0.994 - ETA: 2s - loss: 0.0178 - acc: 0.994 - ETA: 2s - loss: 0.0178 - acc: 0.994 - ETA: 2s - loss: 0.0178 - acc: 0.994 - ETA: 2s - loss: 0.0177 - acc: 0.994 - ETA: 1s - loss: 0.0176 - acc: 0.994 - ETA: 1s - loss: 0.0175 - acc: 0.994 - ETA: 1s - loss: 0.0175 - acc: 0.994 - ETA: 1s - loss: 0.0174 - acc: 0.994 - ETA: 1s - loss: 0.0172 - acc: 0.994 - ETA: 1s - loss: 0.0172 - acc: 0.994 - ETA: 1s - loss: 0.0172 - acc: 0.994 - ETA: 1s - loss: 0.0175 - acc: 0.994 - ETA: 1s - loss: 0.0179 - acc: 0.994 - ETA: 1s - loss: 0.0179 - acc: 0.994 - ETA: 1s - loss: 0.0179 - acc: 0.994 - ETA: 1s - loss: 0.0180 - acc: 0.994 - ETA: 1s - loss: 0.0180 - acc: 0.994 - ETA: 1s - loss: 0.0179 - acc: 0.994 - ETA: 1s - loss: 0.0179 - acc: 0.994 - ETA: 1s - loss: 0.0178 - acc: 0.994 - ETA: 1s - loss: 0.0178 - acc: 0.994 - ETA: 1s - loss: 0.0177 - acc: 0.994 - ETA: 1s - loss: 0.0178 - acc: 0.994 - ETA: 0s - loss: 0.0178 - acc: 0.994 - ETA: 0s - loss: 0.0179 - acc: 0.994 - ETA: 0s - loss: 0.0180 - acc: 0.994 - ETA: 0s - loss: 0.0184 - acc: 0.994 - ETA: 0s - loss: 0.0184 - acc: 0.994 - ETA: 0s - loss: 0.0183 - acc: 0.994 - ETA: 0s - loss: 0.0183 - acc: 0.994 - ETA: 0s - loss: 0.0182 - acc: 0.994 - ETA: 0s - loss: 0.0182 - acc: 0.994 - ETA: 0s - loss: 0.0182 - acc: 0.994 - ETA: 0s - loss: 0.0182 - acc: 0.994 - ETA: 0s - loss: 0.0182 - acc: 0.994 - ETA: 0s - loss: 0.0182 - acc: 0.994 - ETA: 0s - loss: 0.0183 - acc: 0.994 - ETA: 0s - loss: 0.0185 - acc: 0.994 - ETA: 0s - loss: 0.0184 - acc: 0.994 - ETA: 0s - loss: 0.0183 - acc: 0.994 - ETA: 0s - loss: 0.0182 - acc: 0.994 - 7s 137us/sample - loss: 0.0182 - acc: 0.9946 - val_loss: 0.0411 - val_acc: 0.9886\n"
     ]
    }
   ],
   "source": [
    "lr_decay = lambda epoch: 0.0001 + 0.02 * math.pow(1.0 / math.e, epoch / 3.0)\n",
    "decay_callback = LearningRateScheduler(lr_decay, verbose=1)\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, \n",
    "                    validation_split=0.1, callbacks=[decay_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FinX93e1jKz9"
   },
   "outputs": [],
   "source": [
    "model.save('mnistbangla.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ioCGtGB3mkDv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:591: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 22 variables.\n",
      "INFO:tensorflow:Converted 22 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2835548"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model_file('mnistbangla.h5')\n",
    "tflite_model = converter.convert()\n",
    "open('mnistbangla.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "51PTkdoPDOTW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip downloading\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('mnistbangla.tflite')\n",
    "except:\n",
    "    print(\"Skip downloading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mnist_batchnorm.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
